{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 2376,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.042105263157894736,
      "grad_norm": 3.0533721446990967,
      "learning_rate": 0.00019999999999999998,
      "loss": 3.3448,
      "step": 50
    },
    {
      "epoch": 0.08421052631578947,
      "grad_norm": 0.9003844857215881,
      "learning_rate": 0.0002999057465473542,
      "loss": 1.0282,
      "step": 100
    },
    {
      "epoch": 0.12631578947368421,
      "grad_norm": 0.9941118955612183,
      "learning_rate": 0.0002991952989771647,
      "loss": 0.8658,
      "step": 150
    },
    {
      "epoch": 0.16842105263157894,
      "grad_norm": 1.104783058166504,
      "learning_rate": 0.00029779164635834114,
      "loss": 0.8458,
      "step": 200
    },
    {
      "epoch": 0.21052631578947367,
      "grad_norm": 0.5196775794029236,
      "learning_rate": 0.00029570131047198915,
      "loss": 0.8028,
      "step": 250
    },
    {
      "epoch": 0.25263157894736843,
      "grad_norm": 3.0777041912078857,
      "learning_rate": 0.00029293400363076,
      "loss": 0.8025,
      "step": 300
    },
    {
      "epoch": 0.29473684210526313,
      "grad_norm": 0.3544255197048187,
      "learning_rate": 0.00028950258355260177,
      "loss": 0.7886,
      "step": 350
    },
    {
      "epoch": 0.3368421052631579,
      "grad_norm": 0.4355947971343994,
      "learning_rate": 0.00028542299362003723,
      "loss": 0.8006,
      "step": 400
    },
    {
      "epoch": 0.37894736842105264,
      "grad_norm": 0.26231786608695984,
      "learning_rate": 0.0002807141888025392,
      "loss": 0.7899,
      "step": 450
    },
    {
      "epoch": 0.42105263157894735,
      "grad_norm": 1.0064972639083862,
      "learning_rate": 0.000275398047586192,
      "loss": 0.7618,
      "step": 500
    },
    {
      "epoch": 0.4631578947368421,
      "grad_norm": 0.592233419418335,
      "learning_rate": 0.0002694992703198383,
      "loss": 0.7544,
      "step": 550
    },
    {
      "epoch": 0.5052631578947369,
      "grad_norm": 0.5316359996795654,
      "learning_rate": 0.0002630452644500253,
      "loss": 0.7904,
      "step": 600
    },
    {
      "epoch": 0.5473684210526316,
      "grad_norm": 0.6657515168190002,
      "learning_rate": 0.00025606601717798207,
      "loss": 0.7932,
      "step": 650
    },
    {
      "epoch": 0.5894736842105263,
      "grad_norm": 0.6248456835746765,
      "learning_rate": 0.0002485939561303016,
      "loss": 0.7367,
      "step": 700
    },
    {
      "epoch": 0.631578947368421,
      "grad_norm": 0.27708765864372253,
      "learning_rate": 0.0002406637986906913,
      "loss": 0.783,
      "step": 750
    },
    {
      "epoch": 0.6736842105263158,
      "grad_norm": 1.3077120780944824,
      "learning_rate": 0.00023231239069284237,
      "loss": 0.7707,
      "step": 800
    },
    {
      "epoch": 0.7157894736842105,
      "grad_norm": 0.26446738839149475,
      "learning_rate": 0.00022357853522389615,
      "loss": 0.7851,
      "step": 850
    },
    {
      "epoch": 0.7578947368421053,
      "grad_norm": 0.1805991679430008,
      "learning_rate": 0.00021450281233393893,
      "loss": 0.776,
      "step": 900
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.23091977834701538,
      "learning_rate": 0.00020512739048920552,
      "loss": 0.7571,
      "step": 950
    },
    {
      "epoch": 0.8421052631578947,
      "grad_norm": 0.3661544620990753,
      "learning_rate": 0.00019549583064503703,
      "loss": 0.7622,
      "step": 1000
    },
    {
      "epoch": 0.8842105263157894,
      "grad_norm": 0.3858374357223511,
      "learning_rate": 0.00018565288384892595,
      "loss": 0.75,
      "step": 1050
    },
    {
      "epoch": 0.9263157894736842,
      "grad_norm": 0.34982192516326904,
      "learning_rate": 0.00017564428331404519,
      "loss": 0.7543,
      "step": 1100
    },
    {
      "epoch": 0.968421052631579,
      "grad_norm": 0.28002941608428955,
      "learning_rate": 0.00016551653192934694,
      "loss": 0.7194,
      "step": 1150
    },
    {
      "epoch": 1.0101052631578948,
      "grad_norm": 0.19869345426559448,
      "learning_rate": 0.00015531668619352338,
      "loss": 0.7334,
      "step": 1200
    },
    {
      "epoch": 1.0522105263157895,
      "grad_norm": 0.2116238921880722,
      "learning_rate": 0.00014509213757673357,
      "loss": 0.7182,
      "step": 1250
    },
    {
      "epoch": 1.0943157894736841,
      "grad_norm": 0.38917168974876404,
      "learning_rate": 0.0001348903923259555,
      "loss": 0.763,
      "step": 1300
    },
    {
      "epoch": 1.136421052631579,
      "grad_norm": 0.4931308925151825,
      "learning_rate": 0.0001247588507370511,
      "loss": 0.7604,
      "step": 1350
    },
    {
      "epoch": 1.1785263157894736,
      "grad_norm": 0.4709908068180084,
      "learning_rate": 0.00011474458691911099,
      "loss": 0.7429,
      "step": 1400
    },
    {
      "epoch": 1.2206315789473685,
      "grad_norm": 0.44517406821250916,
      "learning_rate": 0.00010489413007435904,
      "loss": 0.7377,
      "step": 1450
    },
    {
      "epoch": 1.2627368421052632,
      "grad_norm": 0.4112227261066437,
      "learning_rate": 9.525324830985315e-05,
      "loss": 0.7395,
      "step": 1500
    },
    {
      "epoch": 1.304842105263158,
      "grad_norm": 0.1988202929496765,
      "learning_rate": 8.586673598545771e-05,
      "loss": 0.74,
      "step": 1550
    },
    {
      "epoch": 1.3469473684210527,
      "grad_norm": 0.391472727060318,
      "learning_rate": 7.677820558612987e-05,
      "loss": 0.7381,
      "step": 1600
    },
    {
      "epoch": 1.3890526315789473,
      "grad_norm": 0.3592124879360199,
      "learning_rate": 6.80298850855435e-05,
      "loss": 0.7164,
      "step": 1650
    },
    {
      "epoch": 1.4311578947368422,
      "grad_norm": 0.6387697458267212,
      "learning_rate": 5.9662421742557726e-05,
      "loss": 0.7489,
      "step": 1700
    },
    {
      "epoch": 1.4732631578947368,
      "grad_norm": 0.43518126010894775,
      "learning_rate": 5.171469324214901e-05,
      "loss": 0.7479,
      "step": 1750
    },
    {
      "epoch": 1.5153684210526315,
      "grad_norm": 0.495944082736969,
      "learning_rate": 4.4223627058302404e-05,
      "loss": 0.708,
      "step": 1800
    },
    {
      "epoch": 1.5574736842105263,
      "grad_norm": 0.252572625875473,
      "learning_rate": 3.72240288781534e-05,
      "loss": 0.7757,
      "step": 1850
    },
    {
      "epoch": 1.5995789473684212,
      "grad_norm": 0.3872673213481903,
      "learning_rate": 3.074842088457341e-05,
      "loss": 0.7192,
      "step": 1900
    },
    {
      "epoch": 1.6416842105263156,
      "grad_norm": 0.3365013003349304,
      "learning_rate": 2.4826890648584353e-05,
      "loss": 0.7537,
      "step": 1950
    },
    {
      "epoch": 1.6837894736842105,
      "grad_norm": 0.32090136408805847,
      "learning_rate": 1.9486951333693296e-05,
      "loss": 0.7332,
      "step": 2000
    },
    {
      "epoch": 1.7258947368421054,
      "grad_norm": 0.3807305097579956,
      "learning_rate": 1.4753413861677604e-05,
      "loss": 0.7469,
      "step": 2050
    },
    {
      "epoch": 1.768,
      "grad_norm": 0.1377033144235611,
      "learning_rate": 1.0648271633777066e-05,
      "loss": 0.7383,
      "step": 2100
    },
    {
      "epoch": 1.8101052631578947,
      "grad_norm": 0.2754567265510559,
      "learning_rate": 7.190598342911358e-06,
      "loss": 0.7579,
      "step": 2150
    },
    {
      "epoch": 1.8522105263157895,
      "grad_norm": 0.39967840909957886,
      "learning_rate": 4.396459351717135e-06,
      "loss": 0.6836,
      "step": 2200
    },
    {
      "epoch": 1.8943157894736842,
      "grad_norm": 0.31880950927734375,
      "learning_rate": 2.2788370481687965e-06,
      "loss": 0.7058,
      "step": 2250
    },
    {
      "epoch": 1.9364210526315788,
      "grad_norm": 0.29337647557258606,
      "learning_rate": 8.475705256022814e-07,
      "loss": 0.7268,
      "step": 2300
    },
    {
      "epoch": 1.9785263157894737,
      "grad_norm": 0.2956278622150421,
      "learning_rate": 1.0930986740621539e-07,
      "loss": 0.7484,
      "step": 2350
    }
  ],
  "logging_steps": 50,
  "max_steps": 2376,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.66173131931648e+18,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
