{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 6692,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002988643156007173,
      "grad_norm": 1.6527650356292725,
      "learning_rate": 0.00019984060569834628,
      "loss": 5.2625,
      "step": 10
    },
    {
      "epoch": 0.005977286312014346,
      "grad_norm": 2.3886430263519287,
      "learning_rate": 0.00019964136282127915,
      "loss": 0.4328,
      "step": 20
    },
    {
      "epoch": 0.008965929468021518,
      "grad_norm": 23.839929580688477,
      "learning_rate": 0.00019948196851962544,
      "loss": 0.3581,
      "step": 30
    },
    {
      "epoch": 0.011954572624028692,
      "grad_norm": 0.6619776487350464,
      "learning_rate": 0.0001992827256425583,
      "loss": 0.2745,
      "step": 40
    },
    {
      "epoch": 0.014943215780035863,
      "grad_norm": 0.816567063331604,
      "learning_rate": 0.00019908348276549115,
      "loss": 0.2209,
      "step": 50
    },
    {
      "epoch": 0.017931858936043037,
      "grad_norm": 1.161149024963379,
      "learning_rate": 0.000198884239888424,
      "loss": 0.1822,
      "step": 60
    },
    {
      "epoch": 0.02092050209205021,
      "grad_norm": 1.827928066253662,
      "learning_rate": 0.00019868499701135685,
      "loss": 0.1674,
      "step": 70
    },
    {
      "epoch": 0.023909145248057383,
      "grad_norm": 0.9073235392570496,
      "learning_rate": 0.00019848575413428972,
      "loss": 0.1489,
      "step": 80
    },
    {
      "epoch": 0.026897788404064555,
      "grad_norm": 0.3723238706588745,
      "learning_rate": 0.00019828651125722258,
      "loss": 0.1285,
      "step": 90
    },
    {
      "epoch": 0.029886431560071727,
      "grad_norm": 0.24917910993099213,
      "learning_rate": 0.00019808726838015542,
      "loss": 0.1195,
      "step": 100
    },
    {
      "epoch": 0.0328750747160789,
      "grad_norm": 0.408407986164093,
      "learning_rate": 0.00019788802550308826,
      "loss": 0.142,
      "step": 110
    },
    {
      "epoch": 0.03586371787208607,
      "grad_norm": 0.3387264609336853,
      "learning_rate": 0.00019768878262602113,
      "loss": 0.1394,
      "step": 120
    },
    {
      "epoch": 0.038852361028093245,
      "grad_norm": 0.3377099335193634,
      "learning_rate": 0.000197489539748954,
      "loss": 0.1366,
      "step": 130
    },
    {
      "epoch": 0.04184100418410042,
      "grad_norm": 0.2298934906721115,
      "learning_rate": 0.00019729029687188686,
      "loss": 0.1242,
      "step": 140
    },
    {
      "epoch": 0.04482964734010759,
      "grad_norm": 0.34191209077835083,
      "learning_rate": 0.0001970910539948197,
      "loss": 0.1315,
      "step": 150
    },
    {
      "epoch": 0.04781829049611477,
      "grad_norm": 0.2727779448032379,
      "learning_rate": 0.00019689181111775254,
      "loss": 0.1146,
      "step": 160
    },
    {
      "epoch": 0.05080693365212194,
      "grad_norm": 0.26662346720695496,
      "learning_rate": 0.0001966925682406854,
      "loss": 0.1196,
      "step": 170
    },
    {
      "epoch": 0.05379557680812911,
      "grad_norm": 0.30877918004989624,
      "learning_rate": 0.00019649332536361827,
      "loss": 0.1133,
      "step": 180
    },
    {
      "epoch": 0.05678421996413628,
      "grad_norm": 0.31615784764289856,
      "learning_rate": 0.00019629408248655113,
      "loss": 0.1218,
      "step": 190
    },
    {
      "epoch": 0.05977286312014345,
      "grad_norm": 0.25706058740615845,
      "learning_rate": 0.00019609483960948397,
      "loss": 0.1055,
      "step": 200
    },
    {
      "epoch": 0.06276150627615062,
      "grad_norm": 0.44107893109321594,
      "learning_rate": 0.0001958955967324168,
      "loss": 0.0939,
      "step": 210
    },
    {
      "epoch": 0.0657501494321578,
      "grad_norm": 0.5649771690368652,
      "learning_rate": 0.00019569635385534968,
      "loss": 0.1062,
      "step": 220
    },
    {
      "epoch": 0.06873879258816497,
      "grad_norm": 0.5295908451080322,
      "learning_rate": 0.00019549711097828254,
      "loss": 0.0985,
      "step": 230
    },
    {
      "epoch": 0.07172743574417215,
      "grad_norm": 0.3441990315914154,
      "learning_rate": 0.0001952978681012154,
      "loss": 0.0894,
      "step": 240
    },
    {
      "epoch": 0.07471607890017933,
      "grad_norm": 0.6827383041381836,
      "learning_rate": 0.00019509862522414825,
      "loss": 0.0967,
      "step": 250
    },
    {
      "epoch": 0.07770472205618649,
      "grad_norm": 0.49421653151512146,
      "learning_rate": 0.00019489938234708108,
      "loss": 0.0954,
      "step": 260
    },
    {
      "epoch": 0.08069336521219367,
      "grad_norm": 0.5266493558883667,
      "learning_rate": 0.00019470013947001395,
      "loss": 0.0878,
      "step": 270
    },
    {
      "epoch": 0.08368200836820083,
      "grad_norm": 0.8169048428535461,
      "learning_rate": 0.00019450089659294682,
      "loss": 0.0902,
      "step": 280
    },
    {
      "epoch": 0.08667065152420801,
      "grad_norm": 0.41464489698410034,
      "learning_rate": 0.00019430165371587968,
      "loss": 0.0912,
      "step": 290
    },
    {
      "epoch": 0.08965929468021518,
      "grad_norm": 0.32870540022850037,
      "learning_rate": 0.00019410241083881252,
      "loss": 0.0854,
      "step": 300
    },
    {
      "epoch": 0.09264793783622235,
      "grad_norm": 0.5191180109977722,
      "learning_rate": 0.00019390316796174536,
      "loss": 0.0727,
      "step": 310
    },
    {
      "epoch": 0.09563658099222953,
      "grad_norm": 0.3675440847873688,
      "learning_rate": 0.00019370392508467822,
      "loss": 0.0726,
      "step": 320
    },
    {
      "epoch": 0.0986252241482367,
      "grad_norm": 0.2940158247947693,
      "learning_rate": 0.0001935046822076111,
      "loss": 0.0662,
      "step": 330
    },
    {
      "epoch": 0.10161386730424388,
      "grad_norm": 0.30654969811439514,
      "learning_rate": 0.00019330543933054396,
      "loss": 0.0884,
      "step": 340
    },
    {
      "epoch": 0.10460251046025104,
      "grad_norm": 0.328194260597229,
      "learning_rate": 0.0001931061964534768,
      "loss": 0.07,
      "step": 350
    },
    {
      "epoch": 0.10759115361625822,
      "grad_norm": 0.3783184587955475,
      "learning_rate": 0.00019290695357640963,
      "loss": 0.0701,
      "step": 360
    },
    {
      "epoch": 0.11057979677226538,
      "grad_norm": 0.34846100211143494,
      "learning_rate": 0.0001927077106993425,
      "loss": 0.07,
      "step": 370
    },
    {
      "epoch": 0.11356843992827256,
      "grad_norm": 0.3684546947479248,
      "learning_rate": 0.00019250846782227536,
      "loss": 0.0786,
      "step": 380
    },
    {
      "epoch": 0.11655708308427974,
      "grad_norm": 0.4065501391887665,
      "learning_rate": 0.00019230922494520823,
      "loss": 0.061,
      "step": 390
    },
    {
      "epoch": 0.1195457262402869,
      "grad_norm": 0.3591947853565216,
      "learning_rate": 0.00019210998206814107,
      "loss": 0.0669,
      "step": 400
    },
    {
      "epoch": 0.12253436939629408,
      "grad_norm": 0.9108840227127075,
      "learning_rate": 0.0001919107391910739,
      "loss": 0.0651,
      "step": 410
    },
    {
      "epoch": 0.12552301255230125,
      "grad_norm": 0.4024782180786133,
      "learning_rate": 0.00019171149631400677,
      "loss": 0.0766,
      "step": 420
    },
    {
      "epoch": 0.12851165570830841,
      "grad_norm": 0.32847630977630615,
      "learning_rate": 0.00019151225343693964,
      "loss": 0.0617,
      "step": 430
    },
    {
      "epoch": 0.1315002988643156,
      "grad_norm": 0.35495084524154663,
      "learning_rate": 0.0001913130105598725,
      "loss": 0.0624,
      "step": 440
    },
    {
      "epoch": 0.13448894202032277,
      "grad_norm": 0.42606478929519653,
      "learning_rate": 0.00019111376768280534,
      "loss": 0.0557,
      "step": 450
    },
    {
      "epoch": 0.13747758517632994,
      "grad_norm": 0.38975510001182556,
      "learning_rate": 0.00019091452480573818,
      "loss": 0.0466,
      "step": 460
    },
    {
      "epoch": 0.14046622833233713,
      "grad_norm": 0.4038951098918915,
      "learning_rate": 0.00019071528192867105,
      "loss": 0.0499,
      "step": 470
    },
    {
      "epoch": 0.1434548714883443,
      "grad_norm": 0.2974458634853363,
      "learning_rate": 0.00019051603905160391,
      "loss": 0.0565,
      "step": 480
    },
    {
      "epoch": 0.14644351464435146,
      "grad_norm": 0.26849159598350525,
      "learning_rate": 0.00019031679617453678,
      "loss": 0.061,
      "step": 490
    },
    {
      "epoch": 0.14943215780035865,
      "grad_norm": 0.3348298668861389,
      "learning_rate": 0.00019011755329746962,
      "loss": 0.051,
      "step": 500
    },
    {
      "epoch": 0.15242080095636582,
      "grad_norm": 0.338979035615921,
      "learning_rate": 0.00018991831042040248,
      "loss": 0.0443,
      "step": 510
    },
    {
      "epoch": 0.15540944411237298,
      "grad_norm": 0.3931303322315216,
      "learning_rate": 0.00018971906754333532,
      "loss": 0.0517,
      "step": 520
    },
    {
      "epoch": 0.15839808726838014,
      "grad_norm": 0.37248608469963074,
      "learning_rate": 0.0001895198246662682,
      "loss": 0.0632,
      "step": 530
    },
    {
      "epoch": 0.16138673042438734,
      "grad_norm": 0.41131746768951416,
      "learning_rate": 0.00018932058178920105,
      "loss": 0.0594,
      "step": 540
    },
    {
      "epoch": 0.1643753735803945,
      "grad_norm": 0.291919469833374,
      "learning_rate": 0.0001891213389121339,
      "loss": 0.0472,
      "step": 550
    },
    {
      "epoch": 0.16736401673640167,
      "grad_norm": 0.5426911115646362,
      "learning_rate": 0.00018892209603506676,
      "loss": 0.0499,
      "step": 560
    },
    {
      "epoch": 0.17035265989240886,
      "grad_norm": 0.21200090646743774,
      "learning_rate": 0.0001887228531579996,
      "loss": 0.0359,
      "step": 570
    },
    {
      "epoch": 0.17334130304841602,
      "grad_norm": 0.39367038011550903,
      "learning_rate": 0.00018852361028093246,
      "loss": 0.0529,
      "step": 580
    },
    {
      "epoch": 0.1763299462044232,
      "grad_norm": 0.1923454999923706,
      "learning_rate": 0.00018832436740386533,
      "loss": 0.0409,
      "step": 590
    },
    {
      "epoch": 0.17931858936043035,
      "grad_norm": 0.2827572524547577,
      "learning_rate": 0.00018812512452679817,
      "loss": 0.0593,
      "step": 600
    },
    {
      "epoch": 0.18230723251643755,
      "grad_norm": 0.42640605568885803,
      "learning_rate": 0.00018792588164973103,
      "loss": 0.0433,
      "step": 610
    },
    {
      "epoch": 0.1852958756724447,
      "grad_norm": 0.2498062551021576,
      "learning_rate": 0.00018772663877266387,
      "loss": 0.0437,
      "step": 620
    },
    {
      "epoch": 0.18828451882845187,
      "grad_norm": 0.17723995447158813,
      "learning_rate": 0.00018752739589559674,
      "loss": 0.0357,
      "step": 630
    },
    {
      "epoch": 0.19127316198445907,
      "grad_norm": 0.43521931767463684,
      "learning_rate": 0.0001873281530185296,
      "loss": 0.0363,
      "step": 640
    },
    {
      "epoch": 0.19426180514046623,
      "grad_norm": 0.34705060720443726,
      "learning_rate": 0.00018712891014146244,
      "loss": 0.0297,
      "step": 650
    },
    {
      "epoch": 0.1972504482964734,
      "grad_norm": 0.5519541501998901,
      "learning_rate": 0.0001869296672643953,
      "loss": 0.0371,
      "step": 660
    },
    {
      "epoch": 0.20023909145248056,
      "grad_norm": 0.5123738050460815,
      "learning_rate": 0.00018673042438732815,
      "loss": 0.044,
      "step": 670
    },
    {
      "epoch": 0.20322773460848775,
      "grad_norm": 0.3546120226383209,
      "learning_rate": 0.000186531181510261,
      "loss": 0.0448,
      "step": 680
    },
    {
      "epoch": 0.20621637776449492,
      "grad_norm": 0.4424424171447754,
      "learning_rate": 0.00018633193863319388,
      "loss": 0.0554,
      "step": 690
    },
    {
      "epoch": 0.20920502092050208,
      "grad_norm": 0.391903281211853,
      "learning_rate": 0.00018613269575612674,
      "loss": 0.0498,
      "step": 700
    },
    {
      "epoch": 0.21219366407650928,
      "grad_norm": 0.3168068528175354,
      "learning_rate": 0.00018593345287905958,
      "loss": 0.0464,
      "step": 710
    },
    {
      "epoch": 0.21518230723251644,
      "grad_norm": 0.30791178345680237,
      "learning_rate": 0.00018573421000199245,
      "loss": 0.0353,
      "step": 720
    },
    {
      "epoch": 0.2181709503885236,
      "grad_norm": 0.20871423184871674,
      "learning_rate": 0.00018553496712492529,
      "loss": 0.0315,
      "step": 730
    },
    {
      "epoch": 0.22115959354453077,
      "grad_norm": 0.9753386974334717,
      "learning_rate": 0.00018533572424785815,
      "loss": 0.0496,
      "step": 740
    },
    {
      "epoch": 0.22414823670053796,
      "grad_norm": 0.3077116310596466,
      "learning_rate": 0.00018513648137079102,
      "loss": 0.0429,
      "step": 750
    },
    {
      "epoch": 0.22713687985654513,
      "grad_norm": 0.2915619909763336,
      "learning_rate": 0.00018493723849372386,
      "loss": 0.0362,
      "step": 760
    },
    {
      "epoch": 0.2301255230125523,
      "grad_norm": 0.3993597626686096,
      "learning_rate": 0.00018473799561665672,
      "loss": 0.0332,
      "step": 770
    },
    {
      "epoch": 0.23311416616855948,
      "grad_norm": 0.38132232427597046,
      "learning_rate": 0.00018453875273958956,
      "loss": 0.0335,
      "step": 780
    },
    {
      "epoch": 0.23610280932456665,
      "grad_norm": 0.4335293471813202,
      "learning_rate": 0.00018433950986252243,
      "loss": 0.0426,
      "step": 790
    },
    {
      "epoch": 0.2390914524805738,
      "grad_norm": 0.9392108917236328,
      "learning_rate": 0.0001841402669854553,
      "loss": 0.0447,
      "step": 800
    },
    {
      "epoch": 0.242080095636581,
      "grad_norm": 0.4741378724575043,
      "learning_rate": 0.00018394102410838813,
      "loss": 0.0286,
      "step": 810
    },
    {
      "epoch": 0.24506873879258817,
      "grad_norm": 0.7919179201126099,
      "learning_rate": 0.000183741781231321,
      "loss": 0.0339,
      "step": 820
    },
    {
      "epoch": 0.24805738194859533,
      "grad_norm": 0.36155351996421814,
      "learning_rate": 0.00018354253835425383,
      "loss": 0.0482,
      "step": 830
    },
    {
      "epoch": 0.2510460251046025,
      "grad_norm": 0.39528554677963257,
      "learning_rate": 0.0001833432954771867,
      "loss": 0.0432,
      "step": 840
    },
    {
      "epoch": 0.25403466826060966,
      "grad_norm": 0.31712526082992554,
      "learning_rate": 0.00018314405260011957,
      "loss": 0.0369,
      "step": 850
    },
    {
      "epoch": 0.25702331141661683,
      "grad_norm": 0.42653265595436096,
      "learning_rate": 0.0001829448097230524,
      "loss": 0.0355,
      "step": 860
    },
    {
      "epoch": 0.26001195457262405,
      "grad_norm": 0.5355985760688782,
      "learning_rate": 0.00018274556684598527,
      "loss": 0.0295,
      "step": 870
    },
    {
      "epoch": 0.2630005977286312,
      "grad_norm": 0.2742578685283661,
      "learning_rate": 0.0001825463239689181,
      "loss": 0.0403,
      "step": 880
    },
    {
      "epoch": 0.2659892408846384,
      "grad_norm": 0.20469117164611816,
      "learning_rate": 0.00018234708109185097,
      "loss": 0.0445,
      "step": 890
    },
    {
      "epoch": 0.26897788404064554,
      "grad_norm": 0.2033003866672516,
      "learning_rate": 0.00018214783821478384,
      "loss": 0.0342,
      "step": 900
    },
    {
      "epoch": 0.2719665271966527,
      "grad_norm": 0.279592365026474,
      "learning_rate": 0.00018194859533771668,
      "loss": 0.0335,
      "step": 910
    },
    {
      "epoch": 0.2749551703526599,
      "grad_norm": 0.34850430488586426,
      "learning_rate": 0.00018174935246064954,
      "loss": 0.0294,
      "step": 920
    },
    {
      "epoch": 0.2779438135086671,
      "grad_norm": 0.36237403750419617,
      "learning_rate": 0.0001815501095835824,
      "loss": 0.0291,
      "step": 930
    },
    {
      "epoch": 0.28093245666467426,
      "grad_norm": 0.44828733801841736,
      "learning_rate": 0.00018135086670651525,
      "loss": 0.0277,
      "step": 940
    },
    {
      "epoch": 0.2839210998206814,
      "grad_norm": 0.5382813215255737,
      "learning_rate": 0.00018115162382944811,
      "loss": 0.0357,
      "step": 950
    },
    {
      "epoch": 0.2869097429766886,
      "grad_norm": 0.2102663218975067,
      "learning_rate": 0.00018095238095238095,
      "loss": 0.0325,
      "step": 960
    },
    {
      "epoch": 0.28989838613269575,
      "grad_norm": 0.5535508394241333,
      "learning_rate": 0.00018075313807531382,
      "loss": 0.0287,
      "step": 970
    },
    {
      "epoch": 0.2928870292887029,
      "grad_norm": 0.4464624226093292,
      "learning_rate": 0.00018055389519824668,
      "loss": 0.0292,
      "step": 980
    },
    {
      "epoch": 0.2958756724447101,
      "grad_norm": 0.48746103048324585,
      "learning_rate": 0.00018035465232117952,
      "loss": 0.0343,
      "step": 990
    },
    {
      "epoch": 0.2988643156007173,
      "grad_norm": 0.5711943507194519,
      "learning_rate": 0.0001801554094441124,
      "loss": 0.0345,
      "step": 1000
    },
    {
      "epoch": 0.30185295875672447,
      "grad_norm": 0.2538006901741028,
      "learning_rate": 0.00017995616656704523,
      "loss": 0.0339,
      "step": 1010
    },
    {
      "epoch": 0.30484160191273163,
      "grad_norm": 0.43772318959236145,
      "learning_rate": 0.0001797569236899781,
      "loss": 0.0344,
      "step": 1020
    },
    {
      "epoch": 0.3078302450687388,
      "grad_norm": 0.47085773944854736,
      "learning_rate": 0.00017955768081291096,
      "loss": 0.0305,
      "step": 1030
    },
    {
      "epoch": 0.31081888822474596,
      "grad_norm": 0.39863574504852295,
      "learning_rate": 0.0001793584379358438,
      "loss": 0.0317,
      "step": 1040
    },
    {
      "epoch": 0.3138075313807531,
      "grad_norm": 0.27893969416618347,
      "learning_rate": 0.00017915919505877666,
      "loss": 0.03,
      "step": 1050
    },
    {
      "epoch": 0.3167961745367603,
      "grad_norm": 0.3160814046859741,
      "learning_rate": 0.0001789599521817095,
      "loss": 0.0272,
      "step": 1060
    },
    {
      "epoch": 0.3197848176927675,
      "grad_norm": 0.24225763976573944,
      "learning_rate": 0.00017876070930464237,
      "loss": 0.0334,
      "step": 1070
    },
    {
      "epoch": 0.3227734608487747,
      "grad_norm": 0.20251232385635376,
      "learning_rate": 0.00017856146642757523,
      "loss": 0.0227,
      "step": 1080
    },
    {
      "epoch": 0.32576210400478184,
      "grad_norm": 0.38732701539993286,
      "learning_rate": 0.00017836222355050807,
      "loss": 0.0447,
      "step": 1090
    },
    {
      "epoch": 0.328750747160789,
      "grad_norm": 0.2639424502849579,
      "learning_rate": 0.00017816298067344094,
      "loss": 0.0416,
      "step": 1100
    },
    {
      "epoch": 0.33173939031679617,
      "grad_norm": 0.3076903223991394,
      "learning_rate": 0.00017796373779637378,
      "loss": 0.0343,
      "step": 1110
    },
    {
      "epoch": 0.33472803347280333,
      "grad_norm": 0.29776236414909363,
      "learning_rate": 0.00017776449491930664,
      "loss": 0.0247,
      "step": 1120
    },
    {
      "epoch": 0.3377166766288105,
      "grad_norm": 0.203467458486557,
      "learning_rate": 0.0001775652520422395,
      "loss": 0.0331,
      "step": 1130
    },
    {
      "epoch": 0.3407053197848177,
      "grad_norm": 0.3131420612335205,
      "learning_rate": 0.00017736600916517237,
      "loss": 0.028,
      "step": 1140
    },
    {
      "epoch": 0.3436939629408249,
      "grad_norm": 0.27958977222442627,
      "learning_rate": 0.0001771667662881052,
      "loss": 0.0271,
      "step": 1150
    },
    {
      "epoch": 0.34668260609683205,
      "grad_norm": 0.19753067195415497,
      "learning_rate": 0.00017696752341103805,
      "loss": 0.0304,
      "step": 1160
    },
    {
      "epoch": 0.3496712492528392,
      "grad_norm": 0.12122849375009537,
      "learning_rate": 0.00017676828053397092,
      "loss": 0.0259,
      "step": 1170
    },
    {
      "epoch": 0.3526598924088464,
      "grad_norm": 0.26303958892822266,
      "learning_rate": 0.00017656903765690378,
      "loss": 0.0306,
      "step": 1180
    },
    {
      "epoch": 0.35564853556485354,
      "grad_norm": 0.5612494945526123,
      "learning_rate": 0.00017636979477983665,
      "loss": 0.0219,
      "step": 1190
    },
    {
      "epoch": 0.3586371787208607,
      "grad_norm": 0.3704439103603363,
      "learning_rate": 0.0001761705519027695,
      "loss": 0.0308,
      "step": 1200
    },
    {
      "epoch": 0.3616258218768679,
      "grad_norm": 0.25676432251930237,
      "learning_rate": 0.00017597130902570233,
      "loss": 0.0287,
      "step": 1210
    },
    {
      "epoch": 0.3646144650328751,
      "grad_norm": 0.7213477492332458,
      "learning_rate": 0.0001757720661486352,
      "loss": 0.0272,
      "step": 1220
    },
    {
      "epoch": 0.36760310818888225,
      "grad_norm": 0.21409808099269867,
      "learning_rate": 0.00017557282327156806,
      "loss": 0.0172,
      "step": 1230
    },
    {
      "epoch": 0.3705917513448894,
      "grad_norm": 0.3140160143375397,
      "learning_rate": 0.00017537358039450092,
      "loss": 0.0229,
      "step": 1240
    },
    {
      "epoch": 0.3735803945008966,
      "grad_norm": 0.4374542832374573,
      "learning_rate": 0.00017517433751743376,
      "loss": 0.0275,
      "step": 1250
    },
    {
      "epoch": 0.37656903765690375,
      "grad_norm": 0.15308700501918793,
      "learning_rate": 0.0001749750946403666,
      "loss": 0.0244,
      "step": 1260
    },
    {
      "epoch": 0.3795576808129109,
      "grad_norm": 1.1339960098266602,
      "learning_rate": 0.00017477585176329947,
      "loss": 0.0319,
      "step": 1270
    },
    {
      "epoch": 0.38254632396891813,
      "grad_norm": 0.1329870969057083,
      "learning_rate": 0.00017457660888623233,
      "loss": 0.0379,
      "step": 1280
    },
    {
      "epoch": 0.3855349671249253,
      "grad_norm": 0.3077971637248993,
      "learning_rate": 0.0001743773660091652,
      "loss": 0.0268,
      "step": 1290
    },
    {
      "epoch": 0.38852361028093246,
      "grad_norm": 0.241575226187706,
      "learning_rate": 0.00017417812313209804,
      "loss": 0.0264,
      "step": 1300
    },
    {
      "epoch": 0.39151225343693963,
      "grad_norm": 0.1036536693572998,
      "learning_rate": 0.00017397888025503087,
      "loss": 0.0208,
      "step": 1310
    },
    {
      "epoch": 0.3945008965929468,
      "grad_norm": 0.4334874153137207,
      "learning_rate": 0.00017377963737796374,
      "loss": 0.0318,
      "step": 1320
    },
    {
      "epoch": 0.39748953974895396,
      "grad_norm": 0.07437077164649963,
      "learning_rate": 0.0001735803945008966,
      "loss": 0.0222,
      "step": 1330
    },
    {
      "epoch": 0.4004781829049611,
      "grad_norm": 0.3177144527435303,
      "learning_rate": 0.00017338115162382947,
      "loss": 0.0266,
      "step": 1340
    },
    {
      "epoch": 0.40346682606096834,
      "grad_norm": 1.0132488012313843,
      "learning_rate": 0.0001731819087467623,
      "loss": 0.0345,
      "step": 1350
    },
    {
      "epoch": 0.4064554692169755,
      "grad_norm": 0.14546307921409607,
      "learning_rate": 0.00017298266586969515,
      "loss": 0.0319,
      "step": 1360
    },
    {
      "epoch": 0.40944411237298267,
      "grad_norm": 0.27521222829818726,
      "learning_rate": 0.00017278342299262801,
      "loss": 0.0284,
      "step": 1370
    },
    {
      "epoch": 0.41243275552898984,
      "grad_norm": 0.10946177691221237,
      "learning_rate": 0.00017258418011556088,
      "loss": 0.0355,
      "step": 1380
    },
    {
      "epoch": 0.415421398684997,
      "grad_norm": 0.11720486730337143,
      "learning_rate": 0.00017238493723849375,
      "loss": 0.0312,
      "step": 1390
    },
    {
      "epoch": 0.41841004184100417,
      "grad_norm": 0.12110030651092529,
      "learning_rate": 0.00017218569436142658,
      "loss": 0.0298,
      "step": 1400
    },
    {
      "epoch": 0.42139868499701133,
      "grad_norm": 0.24194355309009552,
      "learning_rate": 0.00017198645148435942,
      "loss": 0.0259,
      "step": 1410
    },
    {
      "epoch": 0.42438732815301855,
      "grad_norm": 0.21051311492919922,
      "learning_rate": 0.0001717872086072923,
      "loss": 0.0296,
      "step": 1420
    },
    {
      "epoch": 0.4273759713090257,
      "grad_norm": 0.12849994003772736,
      "learning_rate": 0.00017158796573022515,
      "loss": 0.0293,
      "step": 1430
    },
    {
      "epoch": 0.4303646144650329,
      "grad_norm": 0.19795051217079163,
      "learning_rate": 0.00017138872285315802,
      "loss": 0.0221,
      "step": 1440
    },
    {
      "epoch": 0.43335325762104004,
      "grad_norm": 0.14094841480255127,
      "learning_rate": 0.00017118947997609086,
      "loss": 0.0219,
      "step": 1450
    },
    {
      "epoch": 0.4363419007770472,
      "grad_norm": 0.1629544198513031,
      "learning_rate": 0.0001709902370990237,
      "loss": 0.028,
      "step": 1460
    },
    {
      "epoch": 0.4393305439330544,
      "grad_norm": 0.3069627285003662,
      "learning_rate": 0.00017079099422195656,
      "loss": 0.029,
      "step": 1470
    },
    {
      "epoch": 0.44231918708906154,
      "grad_norm": 0.15936343371868134,
      "learning_rate": 0.00017059175134488943,
      "loss": 0.0292,
      "step": 1480
    },
    {
      "epoch": 0.44530783024506876,
      "grad_norm": 0.7369995713233948,
      "learning_rate": 0.0001703925084678223,
      "loss": 0.0257,
      "step": 1490
    },
    {
      "epoch": 0.4482964734010759,
      "grad_norm": 0.11375240236520767,
      "learning_rate": 0.00017019326559075513,
      "loss": 0.0246,
      "step": 1500
    },
    {
      "epoch": 0.4512851165570831,
      "grad_norm": 0.28920358419418335,
      "learning_rate": 0.00016999402271368797,
      "loss": 0.0247,
      "step": 1510
    },
    {
      "epoch": 0.45427375971309025,
      "grad_norm": 0.128509059548378,
      "learning_rate": 0.00016979477983662084,
      "loss": 0.0168,
      "step": 1520
    },
    {
      "epoch": 0.4572624028690974,
      "grad_norm": 0.15317074954509735,
      "learning_rate": 0.0001695955369595537,
      "loss": 0.03,
      "step": 1530
    },
    {
      "epoch": 0.4602510460251046,
      "grad_norm": 0.4193107783794403,
      "learning_rate": 0.00016939629408248657,
      "loss": 0.0254,
      "step": 1540
    },
    {
      "epoch": 0.4632396891811118,
      "grad_norm": 0.3535419702529907,
      "learning_rate": 0.00016919705120541943,
      "loss": 0.0327,
      "step": 1550
    },
    {
      "epoch": 0.46622833233711897,
      "grad_norm": 0.23013897240161896,
      "learning_rate": 0.00016899780832835225,
      "loss": 0.0268,
      "step": 1560
    },
    {
      "epoch": 0.46921697549312613,
      "grad_norm": 0.41872283816337585,
      "learning_rate": 0.0001687985654512851,
      "loss": 0.021,
      "step": 1570
    },
    {
      "epoch": 0.4722056186491333,
      "grad_norm": 0.09600255638360977,
      "learning_rate": 0.00016859932257421798,
      "loss": 0.0202,
      "step": 1580
    },
    {
      "epoch": 0.47519426180514046,
      "grad_norm": 0.0277458056807518,
      "learning_rate": 0.00016840007969715084,
      "loss": 0.0199,
      "step": 1590
    },
    {
      "epoch": 0.4781829049611476,
      "grad_norm": 0.41585013270378113,
      "learning_rate": 0.0001682008368200837,
      "loss": 0.0318,
      "step": 1600
    },
    {
      "epoch": 0.4811715481171548,
      "grad_norm": 0.08509431034326553,
      "learning_rate": 0.00016800159394301655,
      "loss": 0.0224,
      "step": 1610
    },
    {
      "epoch": 0.484160191273162,
      "grad_norm": 0.08298992365598679,
      "learning_rate": 0.00016780235106594939,
      "loss": 0.0306,
      "step": 1620
    },
    {
      "epoch": 0.4871488344291692,
      "grad_norm": 0.1477394700050354,
      "learning_rate": 0.00016760310818888225,
      "loss": 0.0247,
      "step": 1630
    },
    {
      "epoch": 0.49013747758517634,
      "grad_norm": 0.4205509424209595,
      "learning_rate": 0.00016740386531181512,
      "loss": 0.0228,
      "step": 1640
    },
    {
      "epoch": 0.4931261207411835,
      "grad_norm": 0.2123301923274994,
      "learning_rate": 0.00016720462243474798,
      "loss": 0.0229,
      "step": 1650
    },
    {
      "epoch": 0.49611476389719067,
      "grad_norm": 0.13849985599517822,
      "learning_rate": 0.00016700537955768082,
      "loss": 0.0305,
      "step": 1660
    },
    {
      "epoch": 0.49910340705319783,
      "grad_norm": 0.1871674507856369,
      "learning_rate": 0.00016680613668061366,
      "loss": 0.0348,
      "step": 1670
    },
    {
      "epoch": 0.502092050209205,
      "grad_norm": 0.3268793821334839,
      "learning_rate": 0.00016660689380354653,
      "loss": 0.0296,
      "step": 1680
    },
    {
      "epoch": 0.5050806933652122,
      "grad_norm": 0.10327591001987457,
      "learning_rate": 0.0001664076509264794,
      "loss": 0.0287,
      "step": 1690
    },
    {
      "epoch": 0.5080693365212193,
      "grad_norm": 1.1488662958145142,
      "learning_rate": 0.00016620840804941226,
      "loss": 0.0446,
      "step": 1700
    },
    {
      "epoch": 0.5110579796772265,
      "grad_norm": 0.23090760409832,
      "learning_rate": 0.0001660091651723451,
      "loss": 0.0265,
      "step": 1710
    },
    {
      "epoch": 0.5140466228332337,
      "grad_norm": 0.17125557363033295,
      "learning_rate": 0.00016580992229527793,
      "loss": 0.0235,
      "step": 1720
    },
    {
      "epoch": 0.5170352659892409,
      "grad_norm": 0.13279980421066284,
      "learning_rate": 0.0001656106794182108,
      "loss": 0.0233,
      "step": 1730
    },
    {
      "epoch": 0.5200239091452481,
      "grad_norm": 0.13273699581623077,
      "learning_rate": 0.00016541143654114367,
      "loss": 0.0196,
      "step": 1740
    },
    {
      "epoch": 0.5230125523012552,
      "grad_norm": 0.18856070935726166,
      "learning_rate": 0.00016521219366407653,
      "loss": 0.0242,
      "step": 1750
    },
    {
      "epoch": 0.5260011954572624,
      "grad_norm": 0.13371387124061584,
      "learning_rate": 0.00016501295078700937,
      "loss": 0.0191,
      "step": 1760
    },
    {
      "epoch": 0.5289898386132695,
      "grad_norm": 0.19713039696216583,
      "learning_rate": 0.0001648137079099422,
      "loss": 0.0244,
      "step": 1770
    },
    {
      "epoch": 0.5319784817692768,
      "grad_norm": 0.11240435391664505,
      "learning_rate": 0.00016461446503287508,
      "loss": 0.0225,
      "step": 1780
    },
    {
      "epoch": 0.5349671249252839,
      "grad_norm": 0.2523757517337799,
      "learning_rate": 0.00016441522215580794,
      "loss": 0.0244,
      "step": 1790
    },
    {
      "epoch": 0.5379557680812911,
      "grad_norm": 0.549257218837738,
      "learning_rate": 0.0001642159792787408,
      "loss": 0.0338,
      "step": 1800
    },
    {
      "epoch": 0.5409444112372983,
      "grad_norm": 0.15521706640720367,
      "learning_rate": 0.00016401673640167365,
      "loss": 0.0338,
      "step": 1810
    },
    {
      "epoch": 0.5439330543933054,
      "grad_norm": 0.19870004057884216,
      "learning_rate": 0.0001638174935246065,
      "loss": 0.0357,
      "step": 1820
    },
    {
      "epoch": 0.5469216975493126,
      "grad_norm": 0.4226856231689453,
      "learning_rate": 0.00016361825064753935,
      "loss": 0.0261,
      "step": 1830
    },
    {
      "epoch": 0.5499103407053197,
      "grad_norm": 0.4850633442401886,
      "learning_rate": 0.00016341900777047222,
      "loss": 0.0219,
      "step": 1840
    },
    {
      "epoch": 0.552898983861327,
      "grad_norm": 0.2258317619562149,
      "learning_rate": 0.00016321976489340508,
      "loss": 0.023,
      "step": 1850
    },
    {
      "epoch": 0.5558876270173342,
      "grad_norm": 0.46281275153160095,
      "learning_rate": 0.00016302052201633792,
      "loss": 0.0297,
      "step": 1860
    },
    {
      "epoch": 0.5588762701733413,
      "grad_norm": 0.3567805290222168,
      "learning_rate": 0.00016282127913927079,
      "loss": 0.0282,
      "step": 1870
    },
    {
      "epoch": 0.5618649133293485,
      "grad_norm": 0.21814708411693573,
      "learning_rate": 0.00016262203626220362,
      "loss": 0.035,
      "step": 1880
    },
    {
      "epoch": 0.5648535564853556,
      "grad_norm": 0.10656878352165222,
      "learning_rate": 0.0001624227933851365,
      "loss": 0.0272,
      "step": 1890
    },
    {
      "epoch": 0.5678421996413628,
      "grad_norm": 0.10285910964012146,
      "learning_rate": 0.00016222355050806936,
      "loss": 0.0266,
      "step": 1900
    },
    {
      "epoch": 0.57083084279737,
      "grad_norm": 0.13300760090351105,
      "learning_rate": 0.0001620243076310022,
      "loss": 0.0218,
      "step": 1910
    },
    {
      "epoch": 0.5738194859533772,
      "grad_norm": 0.37819167971611023,
      "learning_rate": 0.00016182506475393506,
      "loss": 0.0313,
      "step": 1920
    },
    {
      "epoch": 0.5768081291093844,
      "grad_norm": 0.12918159365653992,
      "learning_rate": 0.0001616258218768679,
      "loss": 0.0194,
      "step": 1930
    },
    {
      "epoch": 0.5797967722653915,
      "grad_norm": 0.11394747346639633,
      "learning_rate": 0.00016142657899980076,
      "loss": 0.0332,
      "step": 1940
    },
    {
      "epoch": 0.5827854154213987,
      "grad_norm": 0.17292146384716034,
      "learning_rate": 0.00016122733612273363,
      "loss": 0.0298,
      "step": 1950
    },
    {
      "epoch": 0.5857740585774058,
      "grad_norm": 0.25624197721481323,
      "learning_rate": 0.00016102809324566647,
      "loss": 0.0244,
      "step": 1960
    },
    {
      "epoch": 0.588762701733413,
      "grad_norm": 0.10667043924331665,
      "learning_rate": 0.00016082885036859933,
      "loss": 0.0238,
      "step": 1970
    },
    {
      "epoch": 0.5917513448894202,
      "grad_norm": 0.09330327808856964,
      "learning_rate": 0.00016062960749153217,
      "loss": 0.0283,
      "step": 1980
    },
    {
      "epoch": 0.5947399880454274,
      "grad_norm": 0.08898202329874039,
      "learning_rate": 0.00016043036461446504,
      "loss": 0.0248,
      "step": 1990
    },
    {
      "epoch": 0.5977286312014346,
      "grad_norm": 0.17094539105892181,
      "learning_rate": 0.0001602311217373979,
      "loss": 0.0213,
      "step": 2000
    },
    {
      "epoch": 0.6007172743574417,
      "grad_norm": 0.08657080680131912,
      "learning_rate": 0.00016003187886033074,
      "loss": 0.0239,
      "step": 2010
    },
    {
      "epoch": 0.6037059175134489,
      "grad_norm": 0.26186317205429077,
      "learning_rate": 0.0001598326359832636,
      "loss": 0.0235,
      "step": 2020
    },
    {
      "epoch": 0.606694560669456,
      "grad_norm": 0.36284250020980835,
      "learning_rate": 0.00015963339310619647,
      "loss": 0.0246,
      "step": 2030
    },
    {
      "epoch": 0.6096832038254633,
      "grad_norm": 0.14475290477275848,
      "learning_rate": 0.0001594341502291293,
      "loss": 0.0194,
      "step": 2040
    },
    {
      "epoch": 0.6126718469814704,
      "grad_norm": 0.18122498691082,
      "learning_rate": 0.00015923490735206218,
      "loss": 0.0144,
      "step": 2050
    },
    {
      "epoch": 0.6156604901374776,
      "grad_norm": 0.05889614298939705,
      "learning_rate": 0.00015903566447499502,
      "loss": 0.0284,
      "step": 2060
    },
    {
      "epoch": 0.6186491332934848,
      "grad_norm": 0.11831976473331451,
      "learning_rate": 0.00015883642159792788,
      "loss": 0.0177,
      "step": 2070
    },
    {
      "epoch": 0.6216377764494919,
      "grad_norm": 0.20349636673927307,
      "learning_rate": 0.00015863717872086075,
      "loss": 0.0325,
      "step": 2080
    },
    {
      "epoch": 0.6246264196054991,
      "grad_norm": 0.09428135305643082,
      "learning_rate": 0.0001584379358437936,
      "loss": 0.0222,
      "step": 2090
    },
    {
      "epoch": 0.6276150627615062,
      "grad_norm": 0.088460773229599,
      "learning_rate": 0.00015823869296672645,
      "loss": 0.0282,
      "step": 2100
    },
    {
      "epoch": 0.6306037059175135,
      "grad_norm": 0.24187450110912323,
      "learning_rate": 0.0001580394500896593,
      "loss": 0.0204,
      "step": 2110
    },
    {
      "epoch": 0.6335923490735206,
      "grad_norm": 0.8119996190071106,
      "learning_rate": 0.00015784020721259216,
      "loss": 0.0218,
      "step": 2120
    },
    {
      "epoch": 0.6365809922295278,
      "grad_norm": 0.3737623989582062,
      "learning_rate": 0.00015764096433552502,
      "loss": 0.0357,
      "step": 2130
    },
    {
      "epoch": 0.639569635385535,
      "grad_norm": 0.28206679224967957,
      "learning_rate": 0.00015744172145845786,
      "loss": 0.0187,
      "step": 2140
    },
    {
      "epoch": 0.6425582785415421,
      "grad_norm": 0.1783139705657959,
      "learning_rate": 0.00015724247858139073,
      "loss": 0.0228,
      "step": 2150
    },
    {
      "epoch": 0.6455469216975493,
      "grad_norm": 0.07681886106729507,
      "learning_rate": 0.00015704323570432357,
      "loss": 0.017,
      "step": 2160
    },
    {
      "epoch": 0.6485355648535565,
      "grad_norm": 0.15293720364570618,
      "learning_rate": 0.00015684399282725643,
      "loss": 0.0303,
      "step": 2170
    },
    {
      "epoch": 0.6515242080095637,
      "grad_norm": 0.13283202052116394,
      "learning_rate": 0.0001566447499501893,
      "loss": 0.0268,
      "step": 2180
    },
    {
      "epoch": 0.6545128511655708,
      "grad_norm": 0.12771251797676086,
      "learning_rate": 0.00015644550707312214,
      "loss": 0.0252,
      "step": 2190
    },
    {
      "epoch": 0.657501494321578,
      "grad_norm": 0.18980175256729126,
      "learning_rate": 0.000156246264196055,
      "loss": 0.0194,
      "step": 2200
    },
    {
      "epoch": 0.6604901374775852,
      "grad_norm": 0.1601235717535019,
      "learning_rate": 0.00015604702131898784,
      "loss": 0.0177,
      "step": 2210
    },
    {
      "epoch": 0.6634787806335923,
      "grad_norm": 0.6210519075393677,
      "learning_rate": 0.0001558477784419207,
      "loss": 0.0174,
      "step": 2220
    },
    {
      "epoch": 0.6664674237895996,
      "grad_norm": 0.21840082108974457,
      "learning_rate": 0.00015564853556485357,
      "loss": 0.029,
      "step": 2230
    },
    {
      "epoch": 0.6694560669456067,
      "grad_norm": 0.11324479430913925,
      "learning_rate": 0.00015544929268778644,
      "loss": 0.0227,
      "step": 2240
    },
    {
      "epoch": 0.6724447101016139,
      "grad_norm": 0.3800654709339142,
      "learning_rate": 0.00015525004981071928,
      "loss": 0.032,
      "step": 2250
    },
    {
      "epoch": 0.675433353257621,
      "grad_norm": 0.28467199206352234,
      "learning_rate": 0.00015505080693365211,
      "loss": 0.0287,
      "step": 2260
    },
    {
      "epoch": 0.6784219964136282,
      "grad_norm": 0.3700927793979645,
      "learning_rate": 0.00015485156405658498,
      "loss": 0.0185,
      "step": 2270
    },
    {
      "epoch": 0.6814106395696354,
      "grad_norm": 0.11174187064170837,
      "learning_rate": 0.00015465232117951785,
      "loss": 0.0198,
      "step": 2280
    },
    {
      "epoch": 0.6843992827256425,
      "grad_norm": 0.15199990570545197,
      "learning_rate": 0.0001544530783024507,
      "loss": 0.0279,
      "step": 2290
    },
    {
      "epoch": 0.6873879258816498,
      "grad_norm": 0.2053574025630951,
      "learning_rate": 0.00015425383542538355,
      "loss": 0.0295,
      "step": 2300
    },
    {
      "epoch": 0.6903765690376569,
      "grad_norm": 0.12446524202823639,
      "learning_rate": 0.0001540545925483164,
      "loss": 0.0199,
      "step": 2310
    },
    {
      "epoch": 0.6933652121936641,
      "grad_norm": 0.10531125217676163,
      "learning_rate": 0.00015385534967124925,
      "loss": 0.0222,
      "step": 2320
    },
    {
      "epoch": 0.6963538553496712,
      "grad_norm": 0.13343551754951477,
      "learning_rate": 0.00015365610679418212,
      "loss": 0.0271,
      "step": 2330
    },
    {
      "epoch": 0.6993424985056784,
      "grad_norm": 0.38253721594810486,
      "learning_rate": 0.00015345686391711499,
      "loss": 0.0191,
      "step": 2340
    },
    {
      "epoch": 0.7023311416616856,
      "grad_norm": 0.29121294617652893,
      "learning_rate": 0.00015325762104004782,
      "loss": 0.024,
      "step": 2350
    },
    {
      "epoch": 0.7053197848176928,
      "grad_norm": 0.1620447188615799,
      "learning_rate": 0.00015305837816298066,
      "loss": 0.0252,
      "step": 2360
    },
    {
      "epoch": 0.7083084279737,
      "grad_norm": 0.29247236251831055,
      "learning_rate": 0.00015285913528591353,
      "loss": 0.0333,
      "step": 2370
    },
    {
      "epoch": 0.7112970711297071,
      "grad_norm": 0.6537700295448303,
      "learning_rate": 0.0001526598924088464,
      "loss": 0.0215,
      "step": 2380
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 0.1089305430650711,
      "learning_rate": 0.00015246064953177926,
      "loss": 0.0232,
      "step": 2390
    },
    {
      "epoch": 0.7172743574417214,
      "grad_norm": 0.1610652655363083,
      "learning_rate": 0.0001522614066547121,
      "loss": 0.0281,
      "step": 2400
    },
    {
      "epoch": 0.7202630005977286,
      "grad_norm": 0.07139451801776886,
      "learning_rate": 0.00015206216377764494,
      "loss": 0.0186,
      "step": 2410
    },
    {
      "epoch": 0.7232516437537359,
      "grad_norm": 0.22597943246364594,
      "learning_rate": 0.0001518629209005778,
      "loss": 0.0239,
      "step": 2420
    },
    {
      "epoch": 0.726240286909743,
      "grad_norm": 0.1021970808506012,
      "learning_rate": 0.00015166367802351067,
      "loss": 0.0221,
      "step": 2430
    },
    {
      "epoch": 0.7292289300657502,
      "grad_norm": 0.07253679633140564,
      "learning_rate": 0.00015146443514644353,
      "loss": 0.0196,
      "step": 2440
    },
    {
      "epoch": 0.7322175732217573,
      "grad_norm": 0.0900270864367485,
      "learning_rate": 0.0001512651922693764,
      "loss": 0.018,
      "step": 2450
    },
    {
      "epoch": 0.7352062163777645,
      "grad_norm": 0.1286773383617401,
      "learning_rate": 0.0001510659493923092,
      "loss": 0.0233,
      "step": 2460
    },
    {
      "epoch": 0.7381948595337716,
      "grad_norm": 0.14084775745868683,
      "learning_rate": 0.00015086670651524208,
      "loss": 0.0298,
      "step": 2470
    },
    {
      "epoch": 0.7411835026897788,
      "grad_norm": 0.36304548382759094,
      "learning_rate": 0.00015066746363817494,
      "loss": 0.0312,
      "step": 2480
    },
    {
      "epoch": 0.7441721458457861,
      "grad_norm": 0.10756581276655197,
      "learning_rate": 0.0001504682207611078,
      "loss": 0.0194,
      "step": 2490
    },
    {
      "epoch": 0.7471607890017932,
      "grad_norm": 0.05047554895281792,
      "learning_rate": 0.00015026897788404068,
      "loss": 0.0196,
      "step": 2500
    },
    {
      "epoch": 0.7501494321578004,
      "grad_norm": 0.10859658569097519,
      "learning_rate": 0.0001500697350069735,
      "loss": 0.02,
      "step": 2510
    },
    {
      "epoch": 0.7531380753138075,
      "grad_norm": 0.12749163806438446,
      "learning_rate": 0.00014987049212990635,
      "loss": 0.0313,
      "step": 2520
    },
    {
      "epoch": 0.7561267184698147,
      "grad_norm": 0.1058250293135643,
      "learning_rate": 0.00014967124925283922,
      "loss": 0.0229,
      "step": 2530
    },
    {
      "epoch": 0.7591153616258218,
      "grad_norm": 0.10426895320415497,
      "learning_rate": 0.00014947200637577208,
      "loss": 0.0255,
      "step": 2540
    },
    {
      "epoch": 0.762104004781829,
      "grad_norm": 0.22144059836864471,
      "learning_rate": 0.00014927276349870495,
      "loss": 0.024,
      "step": 2550
    },
    {
      "epoch": 0.7650926479378363,
      "grad_norm": 0.07985655218362808,
      "learning_rate": 0.00014907352062163776,
      "loss": 0.0186,
      "step": 2560
    },
    {
      "epoch": 0.7680812910938434,
      "grad_norm": 0.15183408558368683,
      "learning_rate": 0.00014887427774457063,
      "loss": 0.0254,
      "step": 2570
    },
    {
      "epoch": 0.7710699342498506,
      "grad_norm": 0.21135349571704865,
      "learning_rate": 0.0001486750348675035,
      "loss": 0.0204,
      "step": 2580
    },
    {
      "epoch": 0.7740585774058577,
      "grad_norm": 0.08919515460729599,
      "learning_rate": 0.00014847579199043636,
      "loss": 0.0189,
      "step": 2590
    },
    {
      "epoch": 0.7770472205618649,
      "grad_norm": 0.23687970638275146,
      "learning_rate": 0.00014827654911336922,
      "loss": 0.0363,
      "step": 2600
    },
    {
      "epoch": 0.780035863717872,
      "grad_norm": 0.23296508193016052,
      "learning_rate": 0.00014807730623630206,
      "loss": 0.0246,
      "step": 2610
    },
    {
      "epoch": 0.7830245068738793,
      "grad_norm": 0.18426652252674103,
      "learning_rate": 0.0001478780633592349,
      "loss": 0.0264,
      "step": 2620
    },
    {
      "epoch": 0.7860131500298865,
      "grad_norm": 0.16990208625793457,
      "learning_rate": 0.00014767882048216777,
      "loss": 0.0261,
      "step": 2630
    },
    {
      "epoch": 0.7890017931858936,
      "grad_norm": 0.3270379900932312,
      "learning_rate": 0.00014747957760510063,
      "loss": 0.0413,
      "step": 2640
    },
    {
      "epoch": 0.7919904363419008,
      "grad_norm": 0.19884930551052094,
      "learning_rate": 0.0001472803347280335,
      "loss": 0.0226,
      "step": 2650
    },
    {
      "epoch": 0.7949790794979079,
      "grad_norm": 0.09695712476968765,
      "learning_rate": 0.00014708109185096634,
      "loss": 0.0244,
      "step": 2660
    },
    {
      "epoch": 0.7979677226539151,
      "grad_norm": 0.07444768399000168,
      "learning_rate": 0.00014688184897389918,
      "loss": 0.0262,
      "step": 2670
    },
    {
      "epoch": 0.8009563658099222,
      "grad_norm": 0.2676144242286682,
      "learning_rate": 0.00014668260609683204,
      "loss": 0.0217,
      "step": 2680
    },
    {
      "epoch": 0.8039450089659295,
      "grad_norm": 0.34846776723861694,
      "learning_rate": 0.0001464833632197649,
      "loss": 0.0286,
      "step": 2690
    },
    {
      "epoch": 0.8069336521219367,
      "grad_norm": 0.09825970977544785,
      "learning_rate": 0.00014628412034269777,
      "loss": 0.0191,
      "step": 2700
    },
    {
      "epoch": 0.8099222952779438,
      "grad_norm": 0.0949350893497467,
      "learning_rate": 0.0001460848774656306,
      "loss": 0.0235,
      "step": 2710
    },
    {
      "epoch": 0.812910938433951,
      "grad_norm": 0.4041672348976135,
      "learning_rate": 0.00014588563458856345,
      "loss": 0.0203,
      "step": 2720
    },
    {
      "epoch": 0.8158995815899581,
      "grad_norm": 0.10028024762868881,
      "learning_rate": 0.00014568639171149632,
      "loss": 0.0242,
      "step": 2730
    },
    {
      "epoch": 0.8188882247459653,
      "grad_norm": 0.12027020007371902,
      "learning_rate": 0.00014548714883442918,
      "loss": 0.0183,
      "step": 2740
    },
    {
      "epoch": 0.8218768679019725,
      "grad_norm": 0.3115919530391693,
      "learning_rate": 0.00014528790595736205,
      "loss": 0.0323,
      "step": 2750
    },
    {
      "epoch": 0.8248655110579797,
      "grad_norm": 0.07406024634838104,
      "learning_rate": 0.00014508866308029489,
      "loss": 0.0243,
      "step": 2760
    },
    {
      "epoch": 0.8278541542139869,
      "grad_norm": 0.07228413224220276,
      "learning_rate": 0.00014488942020322772,
      "loss": 0.0181,
      "step": 2770
    },
    {
      "epoch": 0.830842797369994,
      "grad_norm": 0.17195820808410645,
      "learning_rate": 0.0001446901773261606,
      "loss": 0.0249,
      "step": 2780
    },
    {
      "epoch": 0.8338314405260012,
      "grad_norm": 0.10236883908510208,
      "learning_rate": 0.00014449093444909346,
      "loss": 0.0196,
      "step": 2790
    },
    {
      "epoch": 0.8368200836820083,
      "grad_norm": 0.21196305751800537,
      "learning_rate": 0.00014429169157202632,
      "loss": 0.0224,
      "step": 2800
    },
    {
      "epoch": 0.8398087268380156,
      "grad_norm": 0.2737603783607483,
      "learning_rate": 0.00014409244869495916,
      "loss": 0.0291,
      "step": 2810
    },
    {
      "epoch": 0.8427973699940227,
      "grad_norm": 0.15084430575370789,
      "learning_rate": 0.000143893205817892,
      "loss": 0.0327,
      "step": 2820
    },
    {
      "epoch": 0.8457860131500299,
      "grad_norm": 0.32868874073028564,
      "learning_rate": 0.00014369396294082486,
      "loss": 0.0252,
      "step": 2830
    },
    {
      "epoch": 0.8487746563060371,
      "grad_norm": 0.38392481207847595,
      "learning_rate": 0.00014349472006375773,
      "loss": 0.0217,
      "step": 2840
    },
    {
      "epoch": 0.8517632994620442,
      "grad_norm": 0.1661147028207779,
      "learning_rate": 0.0001432954771866906,
      "loss": 0.029,
      "step": 2850
    },
    {
      "epoch": 0.8547519426180514,
      "grad_norm": 0.39631137251853943,
      "learning_rate": 0.00014309623430962343,
      "loss": 0.0221,
      "step": 2860
    },
    {
      "epoch": 0.8577405857740585,
      "grad_norm": 0.09590127319097519,
      "learning_rate": 0.00014289699143255627,
      "loss": 0.023,
      "step": 2870
    },
    {
      "epoch": 0.8607292289300658,
      "grad_norm": 0.10569959878921509,
      "learning_rate": 0.00014269774855548914,
      "loss": 0.0274,
      "step": 2880
    },
    {
      "epoch": 0.8637178720860729,
      "grad_norm": 0.38407307863235474,
      "learning_rate": 0.000142498505678422,
      "loss": 0.0295,
      "step": 2890
    },
    {
      "epoch": 0.8667065152420801,
      "grad_norm": 0.20973461866378784,
      "learning_rate": 0.00014229926280135487,
      "loss": 0.0263,
      "step": 2900
    },
    {
      "epoch": 0.8696951583980873,
      "grad_norm": 0.4947947859764099,
      "learning_rate": 0.0001421000199242877,
      "loss": 0.0208,
      "step": 2910
    },
    {
      "epoch": 0.8726838015540944,
      "grad_norm": 0.1527549922466278,
      "learning_rate": 0.00014190077704722057,
      "loss": 0.029,
      "step": 2920
    },
    {
      "epoch": 0.8756724447101016,
      "grad_norm": 0.10271021723747253,
      "learning_rate": 0.0001417015341701534,
      "loss": 0.0169,
      "step": 2930
    },
    {
      "epoch": 0.8786610878661087,
      "grad_norm": 0.23032675683498383,
      "learning_rate": 0.00014150229129308628,
      "loss": 0.0202,
      "step": 2940
    },
    {
      "epoch": 0.881649731022116,
      "grad_norm": 0.07894381880760193,
      "learning_rate": 0.00014130304841601914,
      "loss": 0.027,
      "step": 2950
    },
    {
      "epoch": 0.8846383741781231,
      "grad_norm": 0.08936221152544022,
      "learning_rate": 0.00014110380553895198,
      "loss": 0.0212,
      "step": 2960
    },
    {
      "epoch": 0.8876270173341303,
      "grad_norm": 0.2599901556968689,
      "learning_rate": 0.00014090456266188485,
      "loss": 0.023,
      "step": 2970
    },
    {
      "epoch": 0.8906156604901375,
      "grad_norm": 0.10613160580396652,
      "learning_rate": 0.0001407053197848177,
      "loss": 0.02,
      "step": 2980
    },
    {
      "epoch": 0.8936043036461446,
      "grad_norm": 0.14933186769485474,
      "learning_rate": 0.00014050607690775055,
      "loss": 0.0216,
      "step": 2990
    },
    {
      "epoch": 0.8965929468021518,
      "grad_norm": 0.09748496115207672,
      "learning_rate": 0.00014030683403068342,
      "loss": 0.0274,
      "step": 3000
    },
    {
      "epoch": 0.899581589958159,
      "grad_norm": 0.24040012061595917,
      "learning_rate": 0.00014010759115361626,
      "loss": 0.0242,
      "step": 3010
    },
    {
      "epoch": 0.9025702331141662,
      "grad_norm": 0.14769354462623596,
      "learning_rate": 0.00013990834827654912,
      "loss": 0.0295,
      "step": 3020
    },
    {
      "epoch": 0.9055588762701734,
      "grad_norm": 0.0925324410200119,
      "learning_rate": 0.00013970910539948196,
      "loss": 0.0175,
      "step": 3030
    },
    {
      "epoch": 0.9085475194261805,
      "grad_norm": 0.1851949542760849,
      "learning_rate": 0.00013950986252241483,
      "loss": 0.0219,
      "step": 3040
    },
    {
      "epoch": 0.9115361625821877,
      "grad_norm": 0.09779542684555054,
      "learning_rate": 0.0001393106196453477,
      "loss": 0.0096,
      "step": 3050
    },
    {
      "epoch": 0.9145248057381948,
      "grad_norm": 0.3024013340473175,
      "learning_rate": 0.00013911137676828053,
      "loss": 0.03,
      "step": 3060
    },
    {
      "epoch": 0.917513448894202,
      "grad_norm": 0.07164256274700165,
      "learning_rate": 0.0001389121338912134,
      "loss": 0.0223,
      "step": 3070
    },
    {
      "epoch": 0.9205020920502092,
      "grad_norm": 0.11789269745349884,
      "learning_rate": 0.00013871289101414624,
      "loss": 0.0165,
      "step": 3080
    },
    {
      "epoch": 0.9234907352062164,
      "grad_norm": 0.0850718766450882,
      "learning_rate": 0.0001385136481370791,
      "loss": 0.0235,
      "step": 3090
    },
    {
      "epoch": 0.9264793783622236,
      "grad_norm": 0.22429749369621277,
      "learning_rate": 0.00013831440526001197,
      "loss": 0.0189,
      "step": 3100
    },
    {
      "epoch": 0.9294680215182307,
      "grad_norm": 0.20935854315757751,
      "learning_rate": 0.0001381151623829448,
      "loss": 0.031,
      "step": 3110
    },
    {
      "epoch": 0.9324566646742379,
      "grad_norm": 0.36087900400161743,
      "learning_rate": 0.00013791591950587767,
      "loss": 0.0253,
      "step": 3120
    },
    {
      "epoch": 0.935445307830245,
      "grad_norm": 0.10128205269575119,
      "learning_rate": 0.00013771667662881054,
      "loss": 0.0291,
      "step": 3130
    },
    {
      "epoch": 0.9384339509862523,
      "grad_norm": 0.0730513334274292,
      "learning_rate": 0.00013751743375174338,
      "loss": 0.0178,
      "step": 3140
    },
    {
      "epoch": 0.9414225941422594,
      "grad_norm": 0.05579264834523201,
      "learning_rate": 0.00013731819087467624,
      "loss": 0.0182,
      "step": 3150
    },
    {
      "epoch": 0.9444112372982666,
      "grad_norm": 0.1851472705602646,
      "learning_rate": 0.00013711894799760908,
      "loss": 0.0157,
      "step": 3160
    },
    {
      "epoch": 0.9473998804542738,
      "grad_norm": 0.14869792759418488,
      "learning_rate": 0.00013691970512054195,
      "loss": 0.0206,
      "step": 3170
    },
    {
      "epoch": 0.9503885236102809,
      "grad_norm": 0.2746436893939972,
      "learning_rate": 0.0001367204622434748,
      "loss": 0.0248,
      "step": 3180
    },
    {
      "epoch": 0.9533771667662881,
      "grad_norm": 0.10493797808885574,
      "learning_rate": 0.00013652121936640765,
      "loss": 0.0213,
      "step": 3190
    },
    {
      "epoch": 0.9563658099222953,
      "grad_norm": 0.20604945719242096,
      "learning_rate": 0.00013632197648934052,
      "loss": 0.0186,
      "step": 3200
    },
    {
      "epoch": 0.9593544530783025,
      "grad_norm": 0.6862888932228088,
      "learning_rate": 0.00013612273361227336,
      "loss": 0.0357,
      "step": 3210
    },
    {
      "epoch": 0.9623430962343096,
      "grad_norm": 0.09686778485774994,
      "learning_rate": 0.00013592349073520622,
      "loss": 0.0193,
      "step": 3220
    },
    {
      "epoch": 0.9653317393903168,
      "grad_norm": 0.046389300376176834,
      "learning_rate": 0.0001357242478581391,
      "loss": 0.0207,
      "step": 3230
    },
    {
      "epoch": 0.968320382546324,
      "grad_norm": 0.1880854368209839,
      "learning_rate": 0.00013552500498107193,
      "loss": 0.0219,
      "step": 3240
    },
    {
      "epoch": 0.9713090257023311,
      "grad_norm": 0.16059213876724243,
      "learning_rate": 0.0001353257621040048,
      "loss": 0.0198,
      "step": 3250
    },
    {
      "epoch": 0.9742976688583384,
      "grad_norm": 0.2905644178390503,
      "learning_rate": 0.00013512651922693763,
      "loss": 0.0257,
      "step": 3260
    },
    {
      "epoch": 0.9772863120143455,
      "grad_norm": 0.442924439907074,
      "learning_rate": 0.0001349272763498705,
      "loss": 0.0261,
      "step": 3270
    },
    {
      "epoch": 0.9802749551703527,
      "grad_norm": 0.10866061598062515,
      "learning_rate": 0.00013472803347280336,
      "loss": 0.0232,
      "step": 3280
    },
    {
      "epoch": 0.9832635983263598,
      "grad_norm": 0.11432173103094101,
      "learning_rate": 0.0001345287905957362,
      "loss": 0.0227,
      "step": 3290
    },
    {
      "epoch": 0.986252241482367,
      "grad_norm": 0.23249699175357819,
      "learning_rate": 0.00013432954771866907,
      "loss": 0.0243,
      "step": 3300
    },
    {
      "epoch": 0.9892408846383742,
      "grad_norm": 0.4474655091762543,
      "learning_rate": 0.0001341303048416019,
      "loss": 0.0328,
      "step": 3310
    },
    {
      "epoch": 0.9922295277943813,
      "grad_norm": 0.14911705255508423,
      "learning_rate": 0.00013393106196453477,
      "loss": 0.023,
      "step": 3320
    },
    {
      "epoch": 0.9952181709503886,
      "grad_norm": 0.20131860673427582,
      "learning_rate": 0.00013373181908746764,
      "loss": 0.0211,
      "step": 3330
    },
    {
      "epoch": 0.9982068141063957,
      "grad_norm": 0.3459504544734955,
      "learning_rate": 0.0001335325762104005,
      "loss": 0.031,
      "step": 3340
    },
    {
      "epoch": 1.0011954572624029,
      "grad_norm": 0.09771187603473663,
      "learning_rate": 0.00013333333333333334,
      "loss": 0.0217,
      "step": 3350
    },
    {
      "epoch": 1.00418410041841,
      "grad_norm": 0.08071020245552063,
      "learning_rate": 0.00013313409045626618,
      "loss": 0.0152,
      "step": 3360
    },
    {
      "epoch": 1.007172743574417,
      "grad_norm": 0.08261646330356598,
      "learning_rate": 0.00013293484757919904,
      "loss": 0.0265,
      "step": 3370
    },
    {
      "epoch": 1.0101613867304244,
      "grad_norm": 0.11539424955844879,
      "learning_rate": 0.0001327356047021319,
      "loss": 0.0189,
      "step": 3380
    },
    {
      "epoch": 1.0131500298864315,
      "grad_norm": 0.10032708197832108,
      "learning_rate": 0.00013253636182506478,
      "loss": 0.0238,
      "step": 3390
    },
    {
      "epoch": 1.0161386730424387,
      "grad_norm": 0.1327051818370819,
      "learning_rate": 0.00013233711894799761,
      "loss": 0.0223,
      "step": 3400
    },
    {
      "epoch": 1.019127316198446,
      "grad_norm": 0.07641139626502991,
      "learning_rate": 0.00013213787607093048,
      "loss": 0.0217,
      "step": 3410
    },
    {
      "epoch": 1.022115959354453,
      "grad_norm": 0.29255810379981995,
      "learning_rate": 0.00013193863319386332,
      "loss": 0.0261,
      "step": 3420
    },
    {
      "epoch": 1.0251046025104602,
      "grad_norm": 0.2610792815685272,
      "learning_rate": 0.00013173939031679618,
      "loss": 0.0189,
      "step": 3430
    },
    {
      "epoch": 1.0280932456664673,
      "grad_norm": 0.13975565135478973,
      "learning_rate": 0.00013154014743972905,
      "loss": 0.0303,
      "step": 3440
    },
    {
      "epoch": 1.0310818888224746,
      "grad_norm": 0.13828422129154205,
      "learning_rate": 0.0001313409045626619,
      "loss": 0.0259,
      "step": 3450
    },
    {
      "epoch": 1.0340705319784818,
      "grad_norm": 0.07656462490558624,
      "learning_rate": 0.00013114166168559475,
      "loss": 0.0245,
      "step": 3460
    },
    {
      "epoch": 1.0370591751344889,
      "grad_norm": 0.23408427834510803,
      "learning_rate": 0.0001309424188085276,
      "loss": 0.0295,
      "step": 3470
    },
    {
      "epoch": 1.0400478182904962,
      "grad_norm": 0.3685965836048126,
      "learning_rate": 0.00013074317593146046,
      "loss": 0.025,
      "step": 3480
    },
    {
      "epoch": 1.0430364614465033,
      "grad_norm": 0.08586066216230392,
      "learning_rate": 0.00013054393305439332,
      "loss": 0.0221,
      "step": 3490
    },
    {
      "epoch": 1.0460251046025104,
      "grad_norm": 0.2851845622062683,
      "learning_rate": 0.00013034469017732616,
      "loss": 0.0253,
      "step": 3500
    },
    {
      "epoch": 1.0490137477585177,
      "grad_norm": 0.11889433860778809,
      "learning_rate": 0.00013014544730025903,
      "loss": 0.02,
      "step": 3510
    },
    {
      "epoch": 1.0520023909145249,
      "grad_norm": 0.2721366882324219,
      "learning_rate": 0.00012994620442319187,
      "loss": 0.0254,
      "step": 3520
    },
    {
      "epoch": 1.054991034070532,
      "grad_norm": 0.26287299394607544,
      "learning_rate": 0.00012974696154612473,
      "loss": 0.0191,
      "step": 3530
    },
    {
      "epoch": 1.057979677226539,
      "grad_norm": 0.11006227880716324,
      "learning_rate": 0.0001295477186690576,
      "loss": 0.0193,
      "step": 3540
    },
    {
      "epoch": 1.0609683203825464,
      "grad_norm": 0.05241546034812927,
      "learning_rate": 0.00012934847579199046,
      "loss": 0.0187,
      "step": 3550
    },
    {
      "epoch": 1.0639569635385535,
      "grad_norm": 0.0869547426700592,
      "learning_rate": 0.0001291492329149233,
      "loss": 0.0272,
      "step": 3560
    },
    {
      "epoch": 1.0669456066945606,
      "grad_norm": 0.0688159316778183,
      "learning_rate": 0.00012894999003785614,
      "loss": 0.0225,
      "step": 3570
    },
    {
      "epoch": 1.0699342498505677,
      "grad_norm": 0.09197507798671722,
      "learning_rate": 0.000128750747160789,
      "loss": 0.0274,
      "step": 3580
    },
    {
      "epoch": 1.072922893006575,
      "grad_norm": 0.3259459435939789,
      "learning_rate": 0.00012855150428372187,
      "loss": 0.0348,
      "step": 3590
    },
    {
      "epoch": 1.0759115361625822,
      "grad_norm": 0.1786625236272812,
      "learning_rate": 0.00012835226140665474,
      "loss": 0.0289,
      "step": 3600
    },
    {
      "epoch": 1.0789001793185893,
      "grad_norm": 0.2705746293067932,
      "learning_rate": 0.00012815301852958758,
      "loss": 0.0183,
      "step": 3610
    },
    {
      "epoch": 1.0818888224745966,
      "grad_norm": 0.11214379221200943,
      "learning_rate": 0.00012795377565252042,
      "loss": 0.0186,
      "step": 3620
    },
    {
      "epoch": 1.0848774656306037,
      "grad_norm": 0.5076873302459717,
      "learning_rate": 0.00012775453277545328,
      "loss": 0.015,
      "step": 3630
    },
    {
      "epoch": 1.0878661087866108,
      "grad_norm": 0.1080680713057518,
      "learning_rate": 0.00012755528989838615,
      "loss": 0.0187,
      "step": 3640
    },
    {
      "epoch": 1.0908547519426182,
      "grad_norm": 0.07073750346899033,
      "learning_rate": 0.000127356047021319,
      "loss": 0.0189,
      "step": 3650
    },
    {
      "epoch": 1.0938433950986253,
      "grad_norm": 0.07891497015953064,
      "learning_rate": 0.00012715680414425185,
      "loss": 0.0179,
      "step": 3660
    },
    {
      "epoch": 1.0968320382546324,
      "grad_norm": 0.2851013243198395,
      "learning_rate": 0.0001269575612671847,
      "loss": 0.0236,
      "step": 3670
    },
    {
      "epoch": 1.0998206814106395,
      "grad_norm": 0.12470674514770508,
      "learning_rate": 0.00012675831839011756,
      "loss": 0.0251,
      "step": 3680
    },
    {
      "epoch": 1.1028093245666468,
      "grad_norm": 0.05869626998901367,
      "learning_rate": 0.00012655907551305042,
      "loss": 0.0195,
      "step": 3690
    },
    {
      "epoch": 1.105797967722654,
      "grad_norm": 0.15077100694179535,
      "learning_rate": 0.0001263598326359833,
      "loss": 0.0276,
      "step": 3700
    },
    {
      "epoch": 1.108786610878661,
      "grad_norm": 0.8656202554702759,
      "learning_rate": 0.00012616058975891613,
      "loss": 0.0174,
      "step": 3710
    },
    {
      "epoch": 1.1117752540346681,
      "grad_norm": 0.19342944025993347,
      "learning_rate": 0.00012596134688184896,
      "loss": 0.0258,
      "step": 3720
    },
    {
      "epoch": 1.1147638971906755,
      "grad_norm": 0.22728070616722107,
      "learning_rate": 0.00012576210400478183,
      "loss": 0.0165,
      "step": 3730
    },
    {
      "epoch": 1.1177525403466826,
      "grad_norm": 0.3678137958049774,
      "learning_rate": 0.0001255628611277147,
      "loss": 0.0209,
      "step": 3740
    },
    {
      "epoch": 1.1207411835026897,
      "grad_norm": 0.24380668997764587,
      "learning_rate": 0.00012536361825064756,
      "loss": 0.0255,
      "step": 3750
    },
    {
      "epoch": 1.123729826658697,
      "grad_norm": 0.6341326236724854,
      "learning_rate": 0.0001251643753735804,
      "loss": 0.0287,
      "step": 3760
    },
    {
      "epoch": 1.1267184698147041,
      "grad_norm": 0.3734865188598633,
      "learning_rate": 0.00012496513249651324,
      "loss": 0.0213,
      "step": 3770
    },
    {
      "epoch": 1.1297071129707112,
      "grad_norm": 0.12134850025177002,
      "learning_rate": 0.0001247658896194461,
      "loss": 0.0235,
      "step": 3780
    },
    {
      "epoch": 1.1326957561267186,
      "grad_norm": 0.0735279992222786,
      "learning_rate": 0.00012456664674237897,
      "loss": 0.0249,
      "step": 3790
    },
    {
      "epoch": 1.1356843992827257,
      "grad_norm": 0.07717437297105789,
      "learning_rate": 0.00012436740386531184,
      "loss": 0.0202,
      "step": 3800
    },
    {
      "epoch": 1.1386730424387328,
      "grad_norm": 0.12544545531272888,
      "learning_rate": 0.00012416816098824467,
      "loss": 0.017,
      "step": 3810
    },
    {
      "epoch": 1.14166168559474,
      "grad_norm": 0.08709172159433365,
      "learning_rate": 0.00012396891811117751,
      "loss": 0.0174,
      "step": 3820
    },
    {
      "epoch": 1.1446503287507472,
      "grad_norm": 0.15428465604782104,
      "learning_rate": 0.00012376967523411038,
      "loss": 0.0312,
      "step": 3830
    },
    {
      "epoch": 1.1476389719067543,
      "grad_norm": 0.24926643073558807,
      "learning_rate": 0.00012357043235704325,
      "loss": 0.028,
      "step": 3840
    },
    {
      "epoch": 1.1506276150627615,
      "grad_norm": 0.13397879898548126,
      "learning_rate": 0.0001233711894799761,
      "loss": 0.0225,
      "step": 3850
    },
    {
      "epoch": 1.1536162582187686,
      "grad_norm": 0.0923626571893692,
      "learning_rate": 0.00012317194660290895,
      "loss": 0.0176,
      "step": 3860
    },
    {
      "epoch": 1.156604901374776,
      "grad_norm": 0.33379101753234863,
      "learning_rate": 0.0001229727037258418,
      "loss": 0.023,
      "step": 3870
    },
    {
      "epoch": 1.159593544530783,
      "grad_norm": 0.3027518093585968,
      "learning_rate": 0.00012277346084877465,
      "loss": 0.0163,
      "step": 3880
    },
    {
      "epoch": 1.1625821876867901,
      "grad_norm": 0.09325752407312393,
      "learning_rate": 0.00012257421797170752,
      "loss": 0.0243,
      "step": 3890
    },
    {
      "epoch": 1.1655708308427974,
      "grad_norm": 0.05161033570766449,
      "learning_rate": 0.00012237497509464039,
      "loss": 0.0171,
      "step": 3900
    },
    {
      "epoch": 1.1685594739988046,
      "grad_norm": 0.4381527304649353,
      "learning_rate": 0.00012217573221757322,
      "loss": 0.0263,
      "step": 3910
    },
    {
      "epoch": 1.1715481171548117,
      "grad_norm": 0.10025884211063385,
      "learning_rate": 0.00012197648934050608,
      "loss": 0.0222,
      "step": 3920
    },
    {
      "epoch": 1.174536760310819,
      "grad_norm": 0.0650990754365921,
      "learning_rate": 0.00012177724646343893,
      "loss": 0.0271,
      "step": 3930
    },
    {
      "epoch": 1.177525403466826,
      "grad_norm": 0.06580641865730286,
      "learning_rate": 0.0001215780035863718,
      "loss": 0.0237,
      "step": 3940
    },
    {
      "epoch": 1.1805140466228332,
      "grad_norm": 0.21250809729099274,
      "learning_rate": 0.00012137876070930465,
      "loss": 0.0218,
      "step": 3950
    },
    {
      "epoch": 1.1835026897788403,
      "grad_norm": 0.04726763069629669,
      "learning_rate": 0.00012117951783223751,
      "loss": 0.0161,
      "step": 3960
    },
    {
      "epoch": 1.1864913329348477,
      "grad_norm": 0.06206906586885452,
      "learning_rate": 0.00012098027495517035,
      "loss": 0.022,
      "step": 3970
    },
    {
      "epoch": 1.1894799760908548,
      "grad_norm": 0.1603231430053711,
      "learning_rate": 0.0001207810320781032,
      "loss": 0.0273,
      "step": 3980
    },
    {
      "epoch": 1.1924686192468619,
      "grad_norm": 0.06426212191581726,
      "learning_rate": 0.00012058178920103607,
      "loss": 0.0201,
      "step": 3990
    },
    {
      "epoch": 1.195457262402869,
      "grad_norm": 0.08147980272769928,
      "learning_rate": 0.00012038254632396892,
      "loss": 0.0213,
      "step": 4000
    },
    {
      "epoch": 1.1984459055588763,
      "grad_norm": 0.07806557416915894,
      "learning_rate": 0.00012018330344690179,
      "loss": 0.031,
      "step": 4010
    },
    {
      "epoch": 1.2014345487148834,
      "grad_norm": 0.5837501883506775,
      "learning_rate": 0.00011998406056983464,
      "loss": 0.0269,
      "step": 4020
    },
    {
      "epoch": 1.2044231918708905,
      "grad_norm": 0.1511620134115219,
      "learning_rate": 0.00011978481769276748,
      "loss": 0.0275,
      "step": 4030
    },
    {
      "epoch": 1.2074118350268979,
      "grad_norm": 0.09218841791152954,
      "learning_rate": 0.00011958557481570034,
      "loss": 0.0159,
      "step": 4040
    },
    {
      "epoch": 1.210400478182905,
      "grad_norm": 0.44679221510887146,
      "learning_rate": 0.0001193863319386332,
      "loss": 0.0179,
      "step": 4050
    },
    {
      "epoch": 1.213389121338912,
      "grad_norm": 0.09849473834037781,
      "learning_rate": 0.00011918708906156606,
      "loss": 0.0152,
      "step": 4060
    },
    {
      "epoch": 1.2163777644949194,
      "grad_norm": 0.1318138986825943,
      "learning_rate": 0.00011898784618449891,
      "loss": 0.0279,
      "step": 4070
    },
    {
      "epoch": 1.2193664076509265,
      "grad_norm": 0.1491972953081131,
      "learning_rate": 0.00011878860330743175,
      "loss": 0.0192,
      "step": 4080
    },
    {
      "epoch": 1.2223550508069336,
      "grad_norm": 0.13959550857543945,
      "learning_rate": 0.00011858936043036462,
      "loss": 0.0253,
      "step": 4090
    },
    {
      "epoch": 1.2253436939629407,
      "grad_norm": 0.34467628598213196,
      "learning_rate": 0.00011839011755329747,
      "loss": 0.0203,
      "step": 4100
    },
    {
      "epoch": 1.228332337118948,
      "grad_norm": 0.06332847476005554,
      "learning_rate": 0.00011819087467623033,
      "loss": 0.0158,
      "step": 4110
    },
    {
      "epoch": 1.2313209802749552,
      "grad_norm": 0.04309185966849327,
      "learning_rate": 0.00011799163179916319,
      "loss": 0.0234,
      "step": 4120
    },
    {
      "epoch": 1.2343096234309623,
      "grad_norm": 0.08082395792007446,
      "learning_rate": 0.00011779238892209603,
      "loss": 0.0209,
      "step": 4130
    },
    {
      "epoch": 1.2372982665869694,
      "grad_norm": 0.056616462767124176,
      "learning_rate": 0.00011759314604502889,
      "loss": 0.0132,
      "step": 4140
    },
    {
      "epoch": 1.2402869097429767,
      "grad_norm": 0.11236558109521866,
      "learning_rate": 0.00011739390316796174,
      "loss": 0.0154,
      "step": 4150
    },
    {
      "epoch": 1.2432755528989838,
      "grad_norm": 0.05666655674576759,
      "learning_rate": 0.00011719466029089461,
      "loss": 0.0226,
      "step": 4160
    },
    {
      "epoch": 1.246264196054991,
      "grad_norm": 0.06037957966327667,
      "learning_rate": 0.00011699541741382747,
      "loss": 0.0128,
      "step": 4170
    },
    {
      "epoch": 1.2492528392109983,
      "grad_norm": 0.06047959253191948,
      "learning_rate": 0.0001167961745367603,
      "loss": 0.0179,
      "step": 4180
    },
    {
      "epoch": 1.2522414823670054,
      "grad_norm": 0.20813971757888794,
      "learning_rate": 0.00011659693165969317,
      "loss": 0.027,
      "step": 4190
    },
    {
      "epoch": 1.2552301255230125,
      "grad_norm": 0.41445934772491455,
      "learning_rate": 0.00011639768878262602,
      "loss": 0.0245,
      "step": 4200
    },
    {
      "epoch": 1.2582187686790198,
      "grad_norm": 0.06561625748872757,
      "learning_rate": 0.00011619844590555888,
      "loss": 0.0185,
      "step": 4210
    },
    {
      "epoch": 1.261207411835027,
      "grad_norm": 0.06801892071962357,
      "learning_rate": 0.00011599920302849175,
      "loss": 0.0186,
      "step": 4220
    },
    {
      "epoch": 1.264196054991034,
      "grad_norm": 0.6183932423591614,
      "learning_rate": 0.0001157999601514246,
      "loss": 0.0254,
      "step": 4230
    },
    {
      "epoch": 1.2671846981470414,
      "grad_norm": 0.24016757309436798,
      "learning_rate": 0.00011560071727435744,
      "loss": 0.0204,
      "step": 4240
    },
    {
      "epoch": 1.2701733413030485,
      "grad_norm": 0.05813773721456528,
      "learning_rate": 0.00011540147439729029,
      "loss": 0.021,
      "step": 4250
    },
    {
      "epoch": 1.2731619844590556,
      "grad_norm": 0.1778210997581482,
      "learning_rate": 0.00011520223152022316,
      "loss": 0.0254,
      "step": 4260
    },
    {
      "epoch": 1.2761506276150627,
      "grad_norm": 0.07652724534273148,
      "learning_rate": 0.00011500298864315602,
      "loss": 0.0182,
      "step": 4270
    },
    {
      "epoch": 1.2791392707710698,
      "grad_norm": 0.13778528571128845,
      "learning_rate": 0.00011480374576608888,
      "loss": 0.0235,
      "step": 4280
    },
    {
      "epoch": 1.2821279139270771,
      "grad_norm": 0.19517357647418976,
      "learning_rate": 0.00011460450288902171,
      "loss": 0.0191,
      "step": 4290
    },
    {
      "epoch": 1.2851165570830843,
      "grad_norm": 0.0818929523229599,
      "learning_rate": 0.00011440526001195458,
      "loss": 0.0103,
      "step": 4300
    },
    {
      "epoch": 1.2881052002390914,
      "grad_norm": 0.3799493610858917,
      "learning_rate": 0.00011420601713488743,
      "loss": 0.0249,
      "step": 4310
    },
    {
      "epoch": 1.2910938433950987,
      "grad_norm": 0.2936255931854248,
      "learning_rate": 0.0001140067742578203,
      "loss": 0.0221,
      "step": 4320
    },
    {
      "epoch": 1.2940824865511058,
      "grad_norm": 0.4006440341472626,
      "learning_rate": 0.00011380753138075315,
      "loss": 0.0285,
      "step": 4330
    },
    {
      "epoch": 1.297071129707113,
      "grad_norm": 0.056874603033065796,
      "learning_rate": 0.00011360828850368599,
      "loss": 0.0162,
      "step": 4340
    },
    {
      "epoch": 1.3000597728631202,
      "grad_norm": 0.268640398979187,
      "learning_rate": 0.00011340904562661885,
      "loss": 0.0255,
      "step": 4350
    },
    {
      "epoch": 1.3030484160191274,
      "grad_norm": 0.15873795747756958,
      "learning_rate": 0.00011320980274955171,
      "loss": 0.022,
      "step": 4360
    },
    {
      "epoch": 1.3060370591751345,
      "grad_norm": 0.12021871656179428,
      "learning_rate": 0.00011301055987248457,
      "loss": 0.0307,
      "step": 4370
    },
    {
      "epoch": 1.3090257023311418,
      "grad_norm": 0.11762159317731857,
      "learning_rate": 0.00011281131699541742,
      "loss": 0.0244,
      "step": 4380
    },
    {
      "epoch": 1.312014345487149,
      "grad_norm": 0.5648563504219055,
      "learning_rate": 0.00011261207411835026,
      "loss": 0.028,
      "step": 4390
    },
    {
      "epoch": 1.315002988643156,
      "grad_norm": 0.4526767134666443,
      "learning_rate": 0.00011241283124128313,
      "loss": 0.0344,
      "step": 4400
    },
    {
      "epoch": 1.3179916317991631,
      "grad_norm": 0.08380424231290817,
      "learning_rate": 0.00011221358836421598,
      "loss": 0.0269,
      "step": 4410
    },
    {
      "epoch": 1.3209802749551702,
      "grad_norm": 0.05211791396141052,
      "learning_rate": 0.00011201434548714885,
      "loss": 0.0161,
      "step": 4420
    },
    {
      "epoch": 1.3239689181111776,
      "grad_norm": 0.06680437177419662,
      "learning_rate": 0.0001118151026100817,
      "loss": 0.0138,
      "step": 4430
    },
    {
      "epoch": 1.3269575612671847,
      "grad_norm": 0.1964205950498581,
      "learning_rate": 0.00011161585973301456,
      "loss": 0.0204,
      "step": 4440
    },
    {
      "epoch": 1.3299462044231918,
      "grad_norm": 0.06796203553676605,
      "learning_rate": 0.0001114166168559474,
      "loss": 0.0139,
      "step": 4450
    },
    {
      "epoch": 1.3329348475791991,
      "grad_norm": 0.049628421664237976,
      "learning_rate": 0.00011121737397888026,
      "loss": 0.017,
      "step": 4460
    },
    {
      "epoch": 1.3359234907352062,
      "grad_norm": 0.11678426712751389,
      "learning_rate": 0.00011101813110181312,
      "loss": 0.0161,
      "step": 4470
    },
    {
      "epoch": 1.3389121338912133,
      "grad_norm": 0.24535495042800903,
      "learning_rate": 0.00011081888822474597,
      "loss": 0.0347,
      "step": 4480
    },
    {
      "epoch": 1.3419007770472207,
      "grad_norm": 0.15012475848197937,
      "learning_rate": 0.00011061964534767884,
      "loss": 0.0298,
      "step": 4490
    },
    {
      "epoch": 1.3448894202032278,
      "grad_norm": 0.20086318254470825,
      "learning_rate": 0.00011042040247061168,
      "loss": 0.0279,
      "step": 4500
    },
    {
      "epoch": 1.3478780633592349,
      "grad_norm": 0.10981305688619614,
      "learning_rate": 0.00011022115959354453,
      "loss": 0.0269,
      "step": 4510
    },
    {
      "epoch": 1.3508667065152422,
      "grad_norm": 0.2398386299610138,
      "learning_rate": 0.0001100219167164774,
      "loss": 0.0258,
      "step": 4520
    },
    {
      "epoch": 1.3538553496712493,
      "grad_norm": 0.1547887623310089,
      "learning_rate": 0.00010982267383941025,
      "loss": 0.025,
      "step": 4530
    },
    {
      "epoch": 1.3568439928272564,
      "grad_norm": 0.11164970695972443,
      "learning_rate": 0.00010962343096234311,
      "loss": 0.0162,
      "step": 4540
    },
    {
      "epoch": 1.3598326359832635,
      "grad_norm": 0.054570671170949936,
      "learning_rate": 0.00010942418808527595,
      "loss": 0.0137,
      "step": 4550
    },
    {
      "epoch": 1.3628212791392706,
      "grad_norm": 0.09426472336053848,
      "learning_rate": 0.0001092249452082088,
      "loss": 0.0206,
      "step": 4560
    },
    {
      "epoch": 1.365809922295278,
      "grad_norm": 0.08588215708732605,
      "learning_rate": 0.00010902570233114167,
      "loss": 0.0301,
      "step": 4570
    },
    {
      "epoch": 1.368798565451285,
      "grad_norm": 0.09913410246372223,
      "learning_rate": 0.00010882645945407452,
      "loss": 0.018,
      "step": 4580
    },
    {
      "epoch": 1.3717872086072922,
      "grad_norm": 0.08989398181438446,
      "learning_rate": 0.00010862721657700739,
      "loss": 0.0209,
      "step": 4590
    },
    {
      "epoch": 1.3747758517632995,
      "grad_norm": 0.2909718453884125,
      "learning_rate": 0.00010842797369994023,
      "loss": 0.0245,
      "step": 4600
    },
    {
      "epoch": 1.3777644949193066,
      "grad_norm": 0.07320849597454071,
      "learning_rate": 0.00010822873082287308,
      "loss": 0.0169,
      "step": 4610
    },
    {
      "epoch": 1.3807531380753137,
      "grad_norm": 0.07152587920427322,
      "learning_rate": 0.00010802948794580594,
      "loss": 0.0207,
      "step": 4620
    },
    {
      "epoch": 1.383741781231321,
      "grad_norm": 0.08254097402095795,
      "learning_rate": 0.0001078302450687388,
      "loss": 0.017,
      "step": 4630
    },
    {
      "epoch": 1.3867304243873282,
      "grad_norm": 0.05561598017811775,
      "learning_rate": 0.00010763100219167166,
      "loss": 0.0134,
      "step": 4640
    },
    {
      "epoch": 1.3897190675433353,
      "grad_norm": 0.02720886468887329,
      "learning_rate": 0.00010743175931460451,
      "loss": 0.0258,
      "step": 4650
    },
    {
      "epoch": 1.3927077106993426,
      "grad_norm": 0.02454351633787155,
      "learning_rate": 0.00010723251643753735,
      "loss": 0.0136,
      "step": 4660
    },
    {
      "epoch": 1.3956963538553497,
      "grad_norm": 0.3776029646396637,
      "learning_rate": 0.00010703327356047022,
      "loss": 0.0231,
      "step": 4670
    },
    {
      "epoch": 1.3986849970113568,
      "grad_norm": 0.07409818470478058,
      "learning_rate": 0.00010683403068340307,
      "loss": 0.0247,
      "step": 4680
    },
    {
      "epoch": 1.401673640167364,
      "grad_norm": 0.09614018350839615,
      "learning_rate": 0.00010663478780633594,
      "loss": 0.0158,
      "step": 4690
    },
    {
      "epoch": 1.404662283323371,
      "grad_norm": 0.06132633611559868,
      "learning_rate": 0.00010643554492926879,
      "loss": 0.0154,
      "step": 4700
    },
    {
      "epoch": 1.4076509264793784,
      "grad_norm": 0.0467175655066967,
      "learning_rate": 0.00010623630205220163,
      "loss": 0.0214,
      "step": 4710
    },
    {
      "epoch": 1.4106395696353855,
      "grad_norm": 0.16315573453903198,
      "learning_rate": 0.0001060370591751345,
      "loss": 0.023,
      "step": 4720
    },
    {
      "epoch": 1.4136282127913926,
      "grad_norm": 0.0757010206580162,
      "learning_rate": 0.00010583781629806735,
      "loss": 0.015,
      "step": 4730
    },
    {
      "epoch": 1.4166168559474,
      "grad_norm": 0.06556066870689392,
      "learning_rate": 0.00010563857342100021,
      "loss": 0.0192,
      "step": 4740
    },
    {
      "epoch": 1.419605499103407,
      "grad_norm": 0.3732992112636566,
      "learning_rate": 0.00010543933054393306,
      "loss": 0.0158,
      "step": 4750
    },
    {
      "epoch": 1.4225941422594142,
      "grad_norm": 0.04821356385946274,
      "learning_rate": 0.0001052400876668659,
      "loss": 0.0196,
      "step": 4760
    },
    {
      "epoch": 1.4255827854154215,
      "grad_norm": 0.08558809757232666,
      "learning_rate": 0.00010504084478979877,
      "loss": 0.02,
      "step": 4770
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 0.027879152446985245,
      "learning_rate": 0.00010484160191273162,
      "loss": 0.0134,
      "step": 4780
    },
    {
      "epoch": 1.4315600717274357,
      "grad_norm": 0.37129053473472595,
      "learning_rate": 0.00010464235903566449,
      "loss": 0.0235,
      "step": 4790
    },
    {
      "epoch": 1.434548714883443,
      "grad_norm": 0.32428476214408875,
      "learning_rate": 0.00010444311615859734,
      "loss": 0.022,
      "step": 4800
    },
    {
      "epoch": 1.4375373580394502,
      "grad_norm": 0.05663116276264191,
      "learning_rate": 0.00010424387328153018,
      "loss": 0.021,
      "step": 4810
    },
    {
      "epoch": 1.4405260011954573,
      "grad_norm": 0.4277195334434509,
      "learning_rate": 0.00010404463040446304,
      "loss": 0.0218,
      "step": 4820
    },
    {
      "epoch": 1.4435146443514644,
      "grad_norm": 0.2914072871208191,
      "learning_rate": 0.0001038453875273959,
      "loss": 0.0182,
      "step": 4830
    },
    {
      "epoch": 1.4465032875074715,
      "grad_norm": 0.211752250790596,
      "learning_rate": 0.00010364614465032876,
      "loss": 0.0212,
      "step": 4840
    },
    {
      "epoch": 1.4494919306634788,
      "grad_norm": 0.021349335089325905,
      "learning_rate": 0.00010344690177326161,
      "loss": 0.0127,
      "step": 4850
    },
    {
      "epoch": 1.452480573819486,
      "grad_norm": 0.3250557482242584,
      "learning_rate": 0.00010324765889619448,
      "loss": 0.0212,
      "step": 4860
    },
    {
      "epoch": 1.455469216975493,
      "grad_norm": 0.07258600741624832,
      "learning_rate": 0.00010304841601912732,
      "loss": 0.0156,
      "step": 4870
    },
    {
      "epoch": 1.4584578601315004,
      "grad_norm": 0.06772968918085098,
      "learning_rate": 0.00010284917314206017,
      "loss": 0.0237,
      "step": 4880
    },
    {
      "epoch": 1.4614465032875075,
      "grad_norm": 0.07470414787530899,
      "learning_rate": 0.00010264993026499303,
      "loss": 0.0242,
      "step": 4890
    },
    {
      "epoch": 1.4644351464435146,
      "grad_norm": 0.1601262241601944,
      "learning_rate": 0.00010245068738792589,
      "loss": 0.0202,
      "step": 4900
    },
    {
      "epoch": 1.467423789599522,
      "grad_norm": 0.14797461032867432,
      "learning_rate": 0.00010225144451085875,
      "loss": 0.0218,
      "step": 4910
    },
    {
      "epoch": 1.470412432755529,
      "grad_norm": 0.11165042221546173,
      "learning_rate": 0.00010205220163379159,
      "loss": 0.0169,
      "step": 4920
    },
    {
      "epoch": 1.4734010759115361,
      "grad_norm": 0.020678989589214325,
      "learning_rate": 0.00010185295875672444,
      "loss": 0.0126,
      "step": 4930
    },
    {
      "epoch": 1.4763897190675435,
      "grad_norm": 0.13391117751598358,
      "learning_rate": 0.00010165371587965731,
      "loss": 0.0141,
      "step": 4940
    },
    {
      "epoch": 1.4793783622235506,
      "grad_norm": 0.08223254978656769,
      "learning_rate": 0.00010145447300259016,
      "loss": 0.0254,
      "step": 4950
    },
    {
      "epoch": 1.4823670053795577,
      "grad_norm": 0.014079014770686626,
      "learning_rate": 0.00010125523012552303,
      "loss": 0.0126,
      "step": 4960
    },
    {
      "epoch": 1.4853556485355648,
      "grad_norm": 0.06233835220336914,
      "learning_rate": 0.00010105598724845587,
      "loss": 0.019,
      "step": 4970
    },
    {
      "epoch": 1.488344291691572,
      "grad_norm": 0.4696694016456604,
      "learning_rate": 0.00010085674437138872,
      "loss": 0.0185,
      "step": 4980
    },
    {
      "epoch": 1.4913329348475792,
      "grad_norm": 0.44371768832206726,
      "learning_rate": 0.00010065750149432158,
      "loss": 0.0178,
      "step": 4990
    },
    {
      "epoch": 1.4943215780035863,
      "grad_norm": 0.08983178436756134,
      "learning_rate": 0.00010045825861725444,
      "loss": 0.0213,
      "step": 5000
    },
    {
      "epoch": 1.4973102211595934,
      "grad_norm": 2.5334460735321045,
      "learning_rate": 0.0001002590157401873,
      "loss": 0.0356,
      "step": 5010
    },
    {
      "epoch": 1.5002988643156008,
      "grad_norm": 0.59909987449646,
      "learning_rate": 0.00010005977286312014,
      "loss": 0.0202,
      "step": 5020
    },
    {
      "epoch": 1.5032875074716079,
      "grad_norm": 0.0884467363357544,
      "learning_rate": 9.9860529986053e-05,
      "loss": 0.0162,
      "step": 5030
    },
    {
      "epoch": 1.506276150627615,
      "grad_norm": 0.15249331295490265,
      "learning_rate": 9.966128710898586e-05,
      "loss": 0.0274,
      "step": 5040
    },
    {
      "epoch": 1.5092647937836223,
      "grad_norm": 0.12739495933055878,
      "learning_rate": 9.946204423191871e-05,
      "loss": 0.0224,
      "step": 5050
    },
    {
      "epoch": 1.5122534369396294,
      "grad_norm": 0.06117474287748337,
      "learning_rate": 9.926280135485156e-05,
      "loss": 0.0139,
      "step": 5060
    },
    {
      "epoch": 1.5152420800956365,
      "grad_norm": 0.0623280368745327,
      "learning_rate": 9.906355847778443e-05,
      "loss": 0.0158,
      "step": 5070
    },
    {
      "epoch": 1.5182307232516439,
      "grad_norm": 0.19740478694438934,
      "learning_rate": 9.886431560071728e-05,
      "loss": 0.02,
      "step": 5080
    },
    {
      "epoch": 1.5212193664076508,
      "grad_norm": 1.124579668045044,
      "learning_rate": 9.866507272365013e-05,
      "loss": 0.0286,
      "step": 5090
    },
    {
      "epoch": 1.524208009563658,
      "grad_norm": 0.10993179678916931,
      "learning_rate": 9.8465829846583e-05,
      "loss": 0.0228,
      "step": 5100
    },
    {
      "epoch": 1.5271966527196654,
      "grad_norm": 0.29189157485961914,
      "learning_rate": 9.826658696951584e-05,
      "loss": 0.0278,
      "step": 5110
    },
    {
      "epoch": 1.5301852958756723,
      "grad_norm": 0.0717862918972969,
      "learning_rate": 9.80673440924487e-05,
      "loss": 0.0211,
      "step": 5120
    },
    {
      "epoch": 1.5331739390316796,
      "grad_norm": 0.10022412985563278,
      "learning_rate": 9.786810121538155e-05,
      "loss": 0.012,
      "step": 5130
    },
    {
      "epoch": 1.5361625821876868,
      "grad_norm": 0.17608937621116638,
      "learning_rate": 9.76688583383144e-05,
      "loss": 0.0203,
      "step": 5140
    },
    {
      "epoch": 1.5391512253436939,
      "grad_norm": 0.07091005891561508,
      "learning_rate": 9.746961546124727e-05,
      "loss": 0.0208,
      "step": 5150
    },
    {
      "epoch": 1.5421398684997012,
      "grad_norm": 0.0468229204416275,
      "learning_rate": 9.727037258418012e-05,
      "loss": 0.0235,
      "step": 5160
    },
    {
      "epoch": 1.5451285116557083,
      "grad_norm": 0.04939791187644005,
      "learning_rate": 9.707112970711298e-05,
      "loss": 0.019,
      "step": 5170
    },
    {
      "epoch": 1.5481171548117154,
      "grad_norm": 0.08073896169662476,
      "learning_rate": 9.687188683004583e-05,
      "loss": 0.0185,
      "step": 5180
    },
    {
      "epoch": 1.5511057979677227,
      "grad_norm": 0.5572712421417236,
      "learning_rate": 9.667264395297868e-05,
      "loss": 0.0267,
      "step": 5190
    },
    {
      "epoch": 1.5540944411237299,
      "grad_norm": 0.09137009084224701,
      "learning_rate": 9.647340107591155e-05,
      "loss": 0.0218,
      "step": 5200
    },
    {
      "epoch": 1.557083084279737,
      "grad_norm": 0.008239932358264923,
      "learning_rate": 9.62741581988444e-05,
      "loss": 0.0187,
      "step": 5210
    },
    {
      "epoch": 1.5600717274357443,
      "grad_norm": 0.09803462773561478,
      "learning_rate": 9.607491532177725e-05,
      "loss": 0.0311,
      "step": 5220
    },
    {
      "epoch": 1.5630603705917512,
      "grad_norm": 1.0415223836898804,
      "learning_rate": 9.58756724447101e-05,
      "loss": 0.0237,
      "step": 5230
    },
    {
      "epoch": 1.5660490137477585,
      "grad_norm": 0.20754766464233398,
      "learning_rate": 9.567642956764297e-05,
      "loss": 0.0259,
      "step": 5240
    },
    {
      "epoch": 1.5690376569037658,
      "grad_norm": 0.0806807205080986,
      "learning_rate": 9.547718669057582e-05,
      "loss": 0.0214,
      "step": 5250
    },
    {
      "epoch": 1.5720263000597727,
      "grad_norm": 0.22953547537326813,
      "learning_rate": 9.527794381350867e-05,
      "loss": 0.0231,
      "step": 5260
    },
    {
      "epoch": 1.57501494321578,
      "grad_norm": 0.573828399181366,
      "learning_rate": 9.507870093644153e-05,
      "loss": 0.0246,
      "step": 5270
    },
    {
      "epoch": 1.5780035863717872,
      "grad_norm": 0.3197190463542938,
      "learning_rate": 9.487945805937438e-05,
      "loss": 0.0192,
      "step": 5280
    },
    {
      "epoch": 1.5809922295277943,
      "grad_norm": 0.06397917121648788,
      "learning_rate": 9.468021518230724e-05,
      "loss": 0.0182,
      "step": 5290
    },
    {
      "epoch": 1.5839808726838016,
      "grad_norm": 0.08209903538227081,
      "learning_rate": 9.44809723052401e-05,
      "loss": 0.0192,
      "step": 5300
    },
    {
      "epoch": 1.5869695158398087,
      "grad_norm": 0.29338061809539795,
      "learning_rate": 9.428172942817295e-05,
      "loss": 0.0262,
      "step": 5310
    },
    {
      "epoch": 1.5899581589958158,
      "grad_norm": 0.07522349804639816,
      "learning_rate": 9.40824865511058e-05,
      "loss": 0.0235,
      "step": 5320
    },
    {
      "epoch": 1.5929468021518232,
      "grad_norm": 0.061355654150247574,
      "learning_rate": 9.388324367403865e-05,
      "loss": 0.0186,
      "step": 5330
    },
    {
      "epoch": 1.5959354453078303,
      "grad_norm": Infinity,
      "learning_rate": 9.368400079697152e-05,
      "loss": 0.0134,
      "step": 5340
    },
    {
      "epoch": 1.5989240884638374,
      "grad_norm": 0.0826549381017685,
      "learning_rate": 9.350468220761109e-05,
      "loss": 0.0202,
      "step": 5350
    },
    {
      "epoch": 1.6019127316198447,
      "grad_norm": 0.068328857421875,
      "learning_rate": 9.330543933054394e-05,
      "loss": 0.0143,
      "step": 5360
    },
    {
      "epoch": 1.6049013747758516,
      "grad_norm": 0.19650907814502716,
      "learning_rate": 9.310619645347679e-05,
      "loss": 0.0301,
      "step": 5370
    },
    {
      "epoch": 1.607890017931859,
      "grad_norm": 0.3881213665008545,
      "learning_rate": 9.290695357640966e-05,
      "loss": 0.0204,
      "step": 5380
    },
    {
      "epoch": 1.6108786610878663,
      "grad_norm": 0.10184455662965775,
      "learning_rate": 9.27077106993425e-05,
      "loss": 0.0229,
      "step": 5390
    },
    {
      "epoch": 1.6138673042438731,
      "grad_norm": 0.09680860489606857,
      "learning_rate": 9.250846782227536e-05,
      "loss": 0.0255,
      "step": 5400
    },
    {
      "epoch": 1.6168559473998805,
      "grad_norm": 0.12275762856006622,
      "learning_rate": 9.230922494520821e-05,
      "loss": 0.0253,
      "step": 5410
    },
    {
      "epoch": 1.6198445905558876,
      "grad_norm": 0.38839030265808105,
      "learning_rate": 9.210998206814106e-05,
      "loss": 0.0303,
      "step": 5420
    },
    {
      "epoch": 1.6228332337118947,
      "grad_norm": 0.29305121302604675,
      "learning_rate": 9.191073919107393e-05,
      "loss": 0.0172,
      "step": 5430
    },
    {
      "epoch": 1.625821876867902,
      "grad_norm": 0.11360086500644684,
      "learning_rate": 9.171149631400678e-05,
      "loss": 0.019,
      "step": 5440
    },
    {
      "epoch": 1.6288105200239091,
      "grad_norm": 0.07641974091529846,
      "learning_rate": 9.151225343693963e-05,
      "loss": 0.0214,
      "step": 5450
    },
    {
      "epoch": 1.6317991631799162,
      "grad_norm": 0.2069081962108612,
      "learning_rate": 9.131301055987249e-05,
      "loss": 0.0224,
      "step": 5460
    },
    {
      "epoch": 1.6347878063359236,
      "grad_norm": 0.12766458094120026,
      "learning_rate": 9.111376768280534e-05,
      "loss": 0.0127,
      "step": 5470
    },
    {
      "epoch": 1.6377764494919307,
      "grad_norm": 0.2559315860271454,
      "learning_rate": 9.09145248057382e-05,
      "loss": 0.0251,
      "step": 5480
    },
    {
      "epoch": 1.6407650926479378,
      "grad_norm": 0.4797615706920624,
      "learning_rate": 9.071528192867106e-05,
      "loss": 0.0129,
      "step": 5490
    },
    {
      "epoch": 1.6437537358039451,
      "grad_norm": 0.24605312943458557,
      "learning_rate": 9.051603905160391e-05,
      "loss": 0.0229,
      "step": 5500
    },
    {
      "epoch": 1.6467423789599522,
      "grad_norm": 0.05997061729431152,
      "learning_rate": 9.031679617453676e-05,
      "loss": 0.0156,
      "step": 5510
    },
    {
      "epoch": 1.6497310221159593,
      "grad_norm": 0.25467780232429504,
      "learning_rate": 9.011755329746961e-05,
      "loss": 0.0205,
      "step": 5520
    },
    {
      "epoch": 1.6527196652719667,
      "grad_norm": 0.06670321524143219,
      "learning_rate": 8.991831042040248e-05,
      "loss": 0.0167,
      "step": 5530
    },
    {
      "epoch": 1.6557083084279736,
      "grad_norm": 0.05486306920647621,
      "learning_rate": 8.971906754333533e-05,
      "loss": 0.0176,
      "step": 5540
    },
    {
      "epoch": 1.658696951583981,
      "grad_norm": 0.1403500735759735,
      "learning_rate": 8.951982466626818e-05,
      "loss": 0.0221,
      "step": 5550
    },
    {
      "epoch": 1.661685594739988,
      "grad_norm": 0.43488672375679016,
      "learning_rate": 8.932058178920104e-05,
      "loss": 0.0149,
      "step": 5560
    },
    {
      "epoch": 1.6646742378959951,
      "grad_norm": 0.07304771989583969,
      "learning_rate": 8.91213389121339e-05,
      "loss": 0.0275,
      "step": 5570
    },
    {
      "epoch": 1.6676628810520024,
      "grad_norm": 0.10422024875879288,
      "learning_rate": 8.892209603506675e-05,
      "loss": 0.0278,
      "step": 5580
    },
    {
      "epoch": 1.6706515242080096,
      "grad_norm": 0.08010408282279968,
      "learning_rate": 8.87228531579996e-05,
      "loss": 0.0218,
      "step": 5590
    },
    {
      "epoch": 1.6736401673640167,
      "grad_norm": 0.14888927340507507,
      "learning_rate": 8.852361028093246e-05,
      "loss": 0.0217,
      "step": 5600
    },
    {
      "epoch": 1.676628810520024,
      "grad_norm": 0.09091851115226746,
      "learning_rate": 8.832436740386531e-05,
      "loss": 0.0174,
      "step": 5610
    },
    {
      "epoch": 1.679617453676031,
      "grad_norm": 0.0973479375243187,
      "learning_rate": 8.812512452679818e-05,
      "loss": 0.0195,
      "step": 5620
    },
    {
      "epoch": 1.6826060968320382,
      "grad_norm": 0.057560358196496964,
      "learning_rate": 8.792588164973103e-05,
      "loss": 0.0222,
      "step": 5630
    },
    {
      "epoch": 1.6855947399880455,
      "grad_norm": 0.08564557880163193,
      "learning_rate": 8.772663877266388e-05,
      "loss": 0.0205,
      "step": 5640
    },
    {
      "epoch": 1.6885833831440527,
      "grad_norm": 0.09640680998563766,
      "learning_rate": 8.752739589559675e-05,
      "loss": 0.0111,
      "step": 5650
    },
    {
      "epoch": 1.6915720263000598,
      "grad_norm": 0.06965886801481247,
      "learning_rate": 8.732815301852958e-05,
      "loss": 0.0205,
      "step": 5660
    },
    {
      "epoch": 1.694560669456067,
      "grad_norm": 0.09799469262361526,
      "learning_rate": 8.712891014146245e-05,
      "loss": 0.0167,
      "step": 5670
    },
    {
      "epoch": 1.697549312612074,
      "grad_norm": 0.11472633481025696,
      "learning_rate": 8.69296672643953e-05,
      "loss": 0.0128,
      "step": 5680
    },
    {
      "epoch": 1.7005379557680813,
      "grad_norm": 0.1892479807138443,
      "learning_rate": 8.673042438732815e-05,
      "loss": 0.0225,
      "step": 5690
    },
    {
      "epoch": 1.7035265989240884,
      "grad_norm": 0.06948201358318329,
      "learning_rate": 8.653118151026102e-05,
      "loss": 0.0146,
      "step": 5700
    },
    {
      "epoch": 1.7065152420800955,
      "grad_norm": 0.07057878375053406,
      "learning_rate": 8.633193863319386e-05,
      "loss": 0.0192,
      "step": 5710
    },
    {
      "epoch": 1.7095038852361029,
      "grad_norm": 0.06492908298969269,
      "learning_rate": 8.613269575612672e-05,
      "loss": 0.0217,
      "step": 5720
    },
    {
      "epoch": 1.71249252839211,
      "grad_norm": 0.07978533208370209,
      "learning_rate": 8.593345287905958e-05,
      "loss": 0.0165,
      "step": 5730
    },
    {
      "epoch": 1.715481171548117,
      "grad_norm": 0.03494318202137947,
      "learning_rate": 8.573421000199243e-05,
      "loss": 0.0155,
      "step": 5740
    },
    {
      "epoch": 1.7184698147041244,
      "grad_norm": 0.09544974565505981,
      "learning_rate": 8.55349671249253e-05,
      "loss": 0.0211,
      "step": 5750
    },
    {
      "epoch": 1.7214584578601315,
      "grad_norm": 0.5794227123260498,
      "learning_rate": 8.533572424785813e-05,
      "loss": 0.0193,
      "step": 5760
    },
    {
      "epoch": 1.7244471010161386,
      "grad_norm": 0.059126075357198715,
      "learning_rate": 8.5136481370791e-05,
      "loss": 0.0168,
      "step": 5770
    },
    {
      "epoch": 1.727435744172146,
      "grad_norm": 0.1124463602900505,
      "learning_rate": 8.493723849372386e-05,
      "loss": 0.0224,
      "step": 5780
    },
    {
      "epoch": 1.730424387328153,
      "grad_norm": 0.2523098886013031,
      "learning_rate": 8.47379956166567e-05,
      "loss": 0.0205,
      "step": 5790
    },
    {
      "epoch": 1.7334130304841602,
      "grad_norm": 0.06226155161857605,
      "learning_rate": 8.453875273958957e-05,
      "loss": 0.026,
      "step": 5800
    },
    {
      "epoch": 1.7364016736401675,
      "grad_norm": 0.057736195623874664,
      "learning_rate": 8.433950986252242e-05,
      "loss": 0.0259,
      "step": 5810
    },
    {
      "epoch": 1.7393903167961744,
      "grad_norm": 0.08347762376070023,
      "learning_rate": 8.414026698545527e-05,
      "loss": 0.0165,
      "step": 5820
    },
    {
      "epoch": 1.7423789599521817,
      "grad_norm": 0.062181100249290466,
      "learning_rate": 8.394102410838814e-05,
      "loss": 0.0159,
      "step": 5830
    },
    {
      "epoch": 1.7453676031081888,
      "grad_norm": 0.07132449746131897,
      "learning_rate": 8.374178123132098e-05,
      "loss": 0.0263,
      "step": 5840
    },
    {
      "epoch": 1.748356246264196,
      "grad_norm": 0.23617202043533325,
      "learning_rate": 8.354253835425384e-05,
      "loss": 0.037,
      "step": 5850
    },
    {
      "epoch": 1.7513448894202033,
      "grad_norm": 0.10572103410959244,
      "learning_rate": 8.33432954771867e-05,
      "loss": 0.0233,
      "step": 5860
    },
    {
      "epoch": 1.7543335325762104,
      "grad_norm": 0.13266699016094208,
      "learning_rate": 8.314405260011955e-05,
      "loss": 0.0274,
      "step": 5870
    },
    {
      "epoch": 1.7573221757322175,
      "grad_norm": 0.3508816361427307,
      "learning_rate": 8.294480972305241e-05,
      "loss": 0.0194,
      "step": 5880
    },
    {
      "epoch": 1.7603108188882248,
      "grad_norm": 0.08640750497579575,
      "learning_rate": 8.274556684598525e-05,
      "loss": 0.0156,
      "step": 5890
    },
    {
      "epoch": 1.763299462044232,
      "grad_norm": 0.06750691682100296,
      "learning_rate": 8.254632396891812e-05,
      "loss": 0.0196,
      "step": 5900
    },
    {
      "epoch": 1.766288105200239,
      "grad_norm": 0.5263120532035828,
      "learning_rate": 8.234708109185097e-05,
      "loss": 0.0241,
      "step": 5910
    },
    {
      "epoch": 1.7692767483562464,
      "grad_norm": 0.5777484178543091,
      "learning_rate": 8.214783821478382e-05,
      "loss": 0.0147,
      "step": 5920
    },
    {
      "epoch": 1.7722653915122535,
      "grad_norm": 0.09495682269334793,
      "learning_rate": 8.194859533771669e-05,
      "loss": 0.0192,
      "step": 5930
    },
    {
      "epoch": 1.7752540346682606,
      "grad_norm": 0.03109883703291416,
      "learning_rate": 8.174935246064953e-05,
      "loss": 0.0122,
      "step": 5940
    },
    {
      "epoch": 1.778242677824268,
      "grad_norm": 0.2141691893339157,
      "learning_rate": 8.155010958358239e-05,
      "loss": 0.0224,
      "step": 5950
    },
    {
      "epoch": 1.7812313209802748,
      "grad_norm": 0.1440429389476776,
      "learning_rate": 8.135086670651524e-05,
      "loss": 0.0155,
      "step": 5960
    },
    {
      "epoch": 1.7842199641362821,
      "grad_norm": 0.10292816162109375,
      "learning_rate": 8.11516238294481e-05,
      "loss": 0.0199,
      "step": 5970
    },
    {
      "epoch": 1.7872086072922893,
      "grad_norm": 0.10839289426803589,
      "learning_rate": 8.095238095238096e-05,
      "loss": 0.0228,
      "step": 5980
    },
    {
      "epoch": 1.7901972504482964,
      "grad_norm": 0.08730267733335495,
      "learning_rate": 8.075313807531381e-05,
      "loss": 0.0228,
      "step": 5990
    },
    {
      "epoch": 1.7931858936043037,
      "grad_norm": 0.13716687262058258,
      "learning_rate": 8.055389519824667e-05,
      "loss": 0.0202,
      "step": 6000
    },
    {
      "epoch": 1.7961745367603108,
      "grad_norm": 0.09429965913295746,
      "learning_rate": 8.035465232117952e-05,
      "loss": 0.0172,
      "step": 6010
    },
    {
      "epoch": 1.799163179916318,
      "grad_norm": 0.0590001605451107,
      "learning_rate": 8.015540944411237e-05,
      "loss": 0.0164,
      "step": 6020
    },
    {
      "epoch": 1.8021518230723252,
      "grad_norm": 0.08598539233207703,
      "learning_rate": 7.995616656704524e-05,
      "loss": 0.0251,
      "step": 6030
    },
    {
      "epoch": 1.8051404662283324,
      "grad_norm": 0.05760280415415764,
      "learning_rate": 7.975692368997809e-05,
      "loss": 0.0147,
      "step": 6040
    },
    {
      "epoch": 1.8081291093843395,
      "grad_norm": 0.05621614307165146,
      "learning_rate": 7.955768081291094e-05,
      "loss": 0.0209,
      "step": 6050
    },
    {
      "epoch": 1.8111177525403468,
      "grad_norm": 0.13022352755069733,
      "learning_rate": 7.935843793584379e-05,
      "loss": 0.0196,
      "step": 6060
    },
    {
      "epoch": 1.814106395696354,
      "grad_norm": 0.061674267053604126,
      "learning_rate": 7.915919505877665e-05,
      "loss": 0.0185,
      "step": 6070
    },
    {
      "epoch": 1.817095038852361,
      "grad_norm": 0.04969450831413269,
      "learning_rate": 7.895995218170951e-05,
      "loss": 0.0292,
      "step": 6080
    },
    {
      "epoch": 1.8200836820083683,
      "grad_norm": 0.05729348957538605,
      "learning_rate": 7.876070930464236e-05,
      "loss": 0.0209,
      "step": 6090
    },
    {
      "epoch": 1.8230723251643752,
      "grad_norm": 0.07585018873214722,
      "learning_rate": 7.856146642757522e-05,
      "loss": 0.0166,
      "step": 6100
    },
    {
      "epoch": 1.8260609683203826,
      "grad_norm": 0.05550617352128029,
      "learning_rate": 7.836222355050807e-05,
      "loss": 0.0193,
      "step": 6110
    },
    {
      "epoch": 1.8290496114763897,
      "grad_norm": 0.37377071380615234,
      "learning_rate": 7.816298067344093e-05,
      "loss": 0.0154,
      "step": 6120
    },
    {
      "epoch": 1.8320382546323968,
      "grad_norm": 0.004690939094871283,
      "learning_rate": 7.796373779637379e-05,
      "loss": 0.0243,
      "step": 6130
    },
    {
      "epoch": 1.835026897788404,
      "grad_norm": 0.1050785705447197,
      "learning_rate": 7.776449491930664e-05,
      "loss": 0.0214,
      "step": 6140
    },
    {
      "epoch": 1.8380155409444112,
      "grad_norm": 0.2916065752506256,
      "learning_rate": 7.756525204223949e-05,
      "loss": 0.0176,
      "step": 6150
    },
    {
      "epoch": 1.8410041841004183,
      "grad_norm": 0.2519398033618927,
      "learning_rate": 7.736600916517234e-05,
      "loss": 0.0169,
      "step": 6160
    },
    {
      "epoch": 1.8439928272564257,
      "grad_norm": 0.04566087946295738,
      "learning_rate": 7.716676628810521e-05,
      "loss": 0.0192,
      "step": 6170
    },
    {
      "epoch": 1.8469814704124328,
      "grad_norm": 0.09157922118902206,
      "learning_rate": 7.696752341103806e-05,
      "loss": 0.0187,
      "step": 6180
    },
    {
      "epoch": 1.8499701135684399,
      "grad_norm": 0.06818918883800507,
      "learning_rate": 7.676828053397091e-05,
      "loss": 0.0223,
      "step": 6190
    },
    {
      "epoch": 1.8529587567244472,
      "grad_norm": 0.24714559316635132,
      "learning_rate": 7.656903765690378e-05,
      "loss": 0.0187,
      "step": 6200
    },
    {
      "epoch": 1.8559473998804543,
      "grad_norm": 0.11939755827188492,
      "learning_rate": 7.636979477983663e-05,
      "loss": 0.0332,
      "step": 6210
    },
    {
      "epoch": 1.8589360430364614,
      "grad_norm": 0.24929268658161163,
      "learning_rate": 7.617055190276948e-05,
      "loss": 0.0186,
      "step": 6220
    },
    {
      "epoch": 1.8619246861924688,
      "grad_norm": 0.09776908159255981,
      "learning_rate": 7.597130902570233e-05,
      "loss": 0.0212,
      "step": 6230
    },
    {
      "epoch": 1.8649133293484756,
      "grad_norm": 0.07298815995454788,
      "learning_rate": 7.577206614863519e-05,
      "loss": 0.0175,
      "step": 6240
    },
    {
      "epoch": 1.867901972504483,
      "grad_norm": 0.05755692347884178,
      "learning_rate": 7.557282327156805e-05,
      "loss": 0.0175,
      "step": 6250
    },
    {
      "epoch": 1.87089061566049,
      "grad_norm": 0.08202417939901352,
      "learning_rate": 7.53735803945009e-05,
      "loss": 0.0211,
      "step": 6260
    },
    {
      "epoch": 1.8738792588164972,
      "grad_norm": 0.06141951307654381,
      "learning_rate": 7.517433751743376e-05,
      "loss": 0.0235,
      "step": 6270
    },
    {
      "epoch": 1.8768679019725045,
      "grad_norm": 0.050985533744096756,
      "learning_rate": 7.497509464036661e-05,
      "loss": 0.0203,
      "step": 6280
    },
    {
      "epoch": 1.8798565451285116,
      "grad_norm": 0.06459669768810272,
      "learning_rate": 7.477585176329946e-05,
      "loss": 0.0178,
      "step": 6290
    },
    {
      "epoch": 1.8828451882845187,
      "grad_norm": 0.018409566953778267,
      "learning_rate": 7.457660888623233e-05,
      "loss": 0.0164,
      "step": 6300
    },
    {
      "epoch": 1.885833831440526,
      "grad_norm": 0.5409523844718933,
      "learning_rate": 7.437736600916518e-05,
      "loss": 0.0201,
      "step": 6310
    },
    {
      "epoch": 1.8888224745965332,
      "grad_norm": 0.5565452575683594,
      "learning_rate": 7.417812313209803e-05,
      "loss": 0.0245,
      "step": 6320
    },
    {
      "epoch": 1.8918111177525403,
      "grad_norm": 0.3036736845970154,
      "learning_rate": 7.39788802550309e-05,
      "loss": 0.0191,
      "step": 6330
    },
    {
      "epoch": 1.8947997609085476,
      "grad_norm": 0.06656692922115326,
      "learning_rate": 7.377963737796373e-05,
      "loss": 0.0196,
      "step": 6340
    },
    {
      "epoch": 1.8977884040645547,
      "grad_norm": 0.04939775913953781,
      "learning_rate": 7.35803945008966e-05,
      "loss": 0.0158,
      "step": 6350
    },
    {
      "epoch": 1.9007770472205618,
      "grad_norm": 0.06977193057537079,
      "learning_rate": 7.338115162382945e-05,
      "loss": 0.0202,
      "step": 6360
    },
    {
      "epoch": 1.9037656903765692,
      "grad_norm": 0.020563820376992226,
      "learning_rate": 7.31819087467623e-05,
      "loss": 0.0191,
      "step": 6370
    },
    {
      "epoch": 1.906754333532576,
      "grad_norm": 0.16771256923675537,
      "learning_rate": 7.298266586969517e-05,
      "loss": 0.0235,
      "step": 6380
    },
    {
      "epoch": 1.9097429766885834,
      "grad_norm": 0.4608552157878876,
      "learning_rate": 7.278342299262801e-05,
      "loss": 0.0191,
      "step": 6390
    },
    {
      "epoch": 1.9127316198445905,
      "grad_norm": 0.33657318353652954,
      "learning_rate": 7.258418011556088e-05,
      "loss": 0.0295,
      "step": 6400
    },
    {
      "epoch": 1.9157202630005976,
      "grad_norm": 0.29762235283851624,
      "learning_rate": 7.238493723849373e-05,
      "loss": 0.0199,
      "step": 6410
    },
    {
      "epoch": 1.918708906156605,
      "grad_norm": 0.07303456962108612,
      "learning_rate": 7.218569436142658e-05,
      "loss": 0.019,
      "step": 6420
    },
    {
      "epoch": 1.921697549312612,
      "grad_norm": 0.07236289232969284,
      "learning_rate": 7.198645148435945e-05,
      "loss": 0.0181,
      "step": 6430
    },
    {
      "epoch": 1.9246861924686192,
      "grad_norm": 0.2825877368450165,
      "learning_rate": 7.178720860729228e-05,
      "loss": 0.0251,
      "step": 6440
    },
    {
      "epoch": 1.9276748356246265,
      "grad_norm": 0.04337235167622566,
      "learning_rate": 7.158796573022515e-05,
      "loss": 0.01,
      "step": 6450
    },
    {
      "epoch": 1.9306634787806336,
      "grad_norm": 0.21836642920970917,
      "learning_rate": 7.1388722853158e-05,
      "loss": 0.0158,
      "step": 6460
    },
    {
      "epoch": 1.9336521219366407,
      "grad_norm": 0.05063800513744354,
      "learning_rate": 7.118947997609085e-05,
      "loss": 0.0126,
      "step": 6470
    },
    {
      "epoch": 1.936640765092648,
      "grad_norm": 0.1127820834517479,
      "learning_rate": 7.099023709902372e-05,
      "loss": 0.0217,
      "step": 6480
    },
    {
      "epoch": 1.9396294082486552,
      "grad_norm": 0.10941248387098312,
      "learning_rate": 7.079099422195656e-05,
      "loss": 0.0115,
      "step": 6490
    },
    {
      "epoch": 1.9426180514046623,
      "grad_norm": 0.0874798446893692,
      "learning_rate": 7.059175134488942e-05,
      "loss": 0.0158,
      "step": 6500
    },
    {
      "epoch": 1.9456066945606696,
      "grad_norm": 0.03915322571992874,
      "learning_rate": 7.039250846782228e-05,
      "loss": 0.0146,
      "step": 6510
    },
    {
      "epoch": 1.9485953377166765,
      "grad_norm": 0.08024094253778458,
      "learning_rate": 7.019326559075513e-05,
      "loss": 0.0183,
      "step": 6520
    },
    {
      "epoch": 1.9515839808726838,
      "grad_norm": 0.0166227575391531,
      "learning_rate": 6.9994022713688e-05,
      "loss": 0.0174,
      "step": 6530
    },
    {
      "epoch": 1.954572624028691,
      "grad_norm": 0.07705759257078171,
      "learning_rate": 6.979477983662085e-05,
      "loss": 0.0167,
      "step": 6540
    },
    {
      "epoch": 1.957561267184698,
      "grad_norm": 0.08086961507797241,
      "learning_rate": 6.95955369595537e-05,
      "loss": 0.0209,
      "step": 6550
    },
    {
      "epoch": 1.9605499103407054,
      "grad_norm": 0.1888994574546814,
      "learning_rate": 6.939629408248655e-05,
      "loss": 0.0143,
      "step": 6560
    },
    {
      "epoch": 1.9635385534967125,
      "grad_norm": 0.03672477602958679,
      "learning_rate": 6.91970512054194e-05,
      "loss": 0.0137,
      "step": 6570
    },
    {
      "epoch": 1.9665271966527196,
      "grad_norm": 0.236796572804451,
      "learning_rate": 6.899780832835227e-05,
      "loss": 0.0245,
      "step": 6580
    },
    {
      "epoch": 1.969515839808727,
      "grad_norm": 0.07825666666030884,
      "learning_rate": 6.879856545128512e-05,
      "loss": 0.0244,
      "step": 6590
    },
    {
      "epoch": 1.972504482964734,
      "grad_norm": 0.11523757129907608,
      "learning_rate": 6.859932257421797e-05,
      "loss": 0.0271,
      "step": 6600
    },
    {
      "epoch": 1.9754931261207411,
      "grad_norm": 0.11864722520112991,
      "learning_rate": 6.840007969715084e-05,
      "loss": 0.0146,
      "step": 6610
    },
    {
      "epoch": 1.9784817692767485,
      "grad_norm": 0.016611067578196526,
      "learning_rate": 6.820083682008368e-05,
      "loss": 0.0128,
      "step": 6620
    },
    {
      "epoch": 1.9814704124327556,
      "grad_norm": 0.06279687583446503,
      "learning_rate": 6.800159394301654e-05,
      "loss": 0.0193,
      "step": 6630
    },
    {
      "epoch": 1.9844590555887627,
      "grad_norm": 0.0503932423889637,
      "learning_rate": 6.78023510659494e-05,
      "loss": 0.0161,
      "step": 6640
    },
    {
      "epoch": 1.98744769874477,
      "grad_norm": 0.06006445735692978,
      "learning_rate": 6.760310818888225e-05,
      "loss": 0.0187,
      "step": 6650
    },
    {
      "epoch": 1.990436341900777,
      "grad_norm": 0.05339529737830162,
      "learning_rate": 6.740386531181511e-05,
      "loss": 0.0217,
      "step": 6660
    },
    {
      "epoch": 1.9934249850567842,
      "grad_norm": 0.08899844437837601,
      "learning_rate": 6.720462243474796e-05,
      "loss": 0.0131,
      "step": 6670
    },
    {
      "epoch": 1.9964136282127916,
      "grad_norm": 0.09701468050479889,
      "learning_rate": 6.700537955768082e-05,
      "loss": 0.0218,
      "step": 6680
    },
    {
      "epoch": 1.9994022713687984,
      "grad_norm": 0.1537855714559555,
      "learning_rate": 6.680613668061367e-05,
      "loss": 0.0244,
      "step": 6690
    }
  ],
  "logging_steps": 10,
  "max_steps": 10038,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5.851480732572058e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
